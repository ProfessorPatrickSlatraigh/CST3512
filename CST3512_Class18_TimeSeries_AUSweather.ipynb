{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorPatrickSlatraigh/CST3512/blob/main/CST3512_Class18_TimeSeries_AUSweather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qv1jTpsGbYr"
      },
      "source": [
        "#CST3512 Class - 18    \n",
        "**Time Series Analysis**         \n",
        "**Australia Weather and Wine Sales Data**    \n",
        "    \n",
        "1. What is **time series**?    \n",
        "2. Working with **time series** in `Pandas`    \n",
        "3. \"Daily minimum temperatures in Melbourne\" dataset    \n",
        "4. **Time series** data wrangling    \n",
        "5. Resampling **time series** data    \n",
        "6. **Time series** Rolling Average (Moving Average, Running Average)\n",
        "7. Exercise: **Time Series** and Forecasting\n",
        "    \n",
        "    \n",
        "<center><i>This notebook is available online at <a href=https://bit.ly/cst3512cl18>bit.ly/cst3512cl18</a></i></center>    \n",
        "    \n",
        "*courtesy of Professor Elena Filatova, CUNY CityTech, 2022; updated 2023 by Professor Patrick.* \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Housekeeping    \n",
        "\n",
        "Imports and intialization required for this notebook    "
      ],
      "metadata": {
        "id": "4O8ocxJk8CVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas library \n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "U4j9FX7c70Qj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib library objects\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams"
      ],
      "metadata": {
        "id": "Il3LgUcIJJ_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "A4avTCspsgX2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6S_bj729qwZ"
      },
      "source": [
        "##1.  What is **time series**?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t8MRbpE9rq-"
      },
      "source": [
        "Readings:\n",
        "* [Time Series Analysis with Pandas](https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/)\n",
        "* [Brief Tutorial](https://towardsdatascience.com/time-series-analysis-for-beginners-8a200552e332)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWu6YHzdciQy"
      },
      "source": [
        "\n",
        "A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data. A time series can be taken on any variable that changes over time.\n",
        "\n",
        "The usage of time series models is twofold:\n",
        "\n",
        "* Obtain an understanding of the underlying forces and structure that produced the observed data;\n",
        "* Fit a model and proceed to forecasting, monitoring or even feedback and feedforward control.\n",
        "\n",
        "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, intelligent transport and trajectory forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and largely in any domain of applied science and engineering which involves temporal measurements.\n",
        "\n",
        "Time series are very frequently plotted via line charts.\n",
        "\n",
        "Here is information on a few time series examples in the real world:\n",
        "\n",
        "* [Central England Temperatures 1659-2016](http://clivebest.com/blog/?p=7603)\n",
        "* [U.S. Real GDP Per Capita (1900 â€“ 2017): Current Economy vs Historical Trend Line](https://bfi.uchicago.edu/insight/chart/u-s-real-gdp-per-capita-1900-2017-current-economy-vs-historical-trendline/)\n",
        "* [New York City's overall water consumption](https://www.reddit.com/r/dataisbeautiful/comments/9tzmkp/oc_surprisingly_new_york_citys_overall_water/)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "P2j8yws3sLbM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW59byULjJLg"
      },
      "source": [
        "##2. Working with **time series** in pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSmclFjLjMaP"
      },
      "source": [
        "Pandas has proven very successful as a tool for working with time series data, especially in the financial data analysis space. Using the [NumPy](https://numpy.org/) `datetime64` and `timedelta64` dtypes, pandas consolidated a large number of features from other Python libraries as well as created a tremendous amount of new functionality for manipulating time series data.\n",
        "\n",
        "In working with time series data, you will frequently seek to:\n",
        "\n",
        "* generate sequences of fixed-frequency dates and time spans\n",
        "* conform or convert time series to a particular frequency\n",
        "* compute \"relative\" dates based on various non-standard time increments (e.g. 5 business days before the last business day of the year) or \"roll\" dates forward or backward\n",
        "\n",
        "The following examples demonstrate how to work with time, date and datetime data using pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.a `.daterange()`"
      ],
      "metadata": {
        "id": "ogZFCVuDBzpd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdLF3QI4jZc3"
      },
      "source": [
        "First of all, let's generate a list of datetime values for 3 subsequent days starting from **03/01/2023** with the interval equals to a **one hour interval**. The [date_range](https://pandas.pydata.org/docs/reference/api/pandas.date_range.html?highlight=date_range) function can return such list in [DatetimeIndex](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.strftime.html) format. We simply  define the left bound for generating dates start (`03/01/2023` in our case), the right bound for generating dates end or the amount of intervals periods (`3*24` in this case, because we are going to cover three days) and preferable frequency freq ('H' in this case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhj1y80Xel3n"
      },
      "source": [
        "example_range = pd.date_range(start='3/01/2023', periods=3*24, freq='H')\n",
        "print(\"Amount of elements:\", len(example_range.values))\n",
        "example_range[:25]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmhsmBhmjr_X"
      },
      "source": [
        "In the same way we can define any other period in the `freq` attribute, for example, days. The full list of possible values can be found [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html).\n",
        "\n",
        "Time series can be created that can be manipulated naturally and easily. The first step to create the range of dates for the time series (as mentioned above). The `dates` **.datarange()** below starts at `2023-01-25` and ends at `2023-02-25`. Frequency of the data is one month (`freq='D'`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzrf-v9vj4g2"
      },
      "source": [
        "dates = pd.date_range('2023-01-25', '2023-02-24', freq='D')\n",
        "dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.b `.to_datetime()`    "
      ],
      "metadata": {
        "id": "wrfvDSftB8jF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CODxzcJkdag"
      },
      "source": [
        "\n",
        "To convert a `Series` or list-like object of date-like objects e.g. strings, epochs, or a mixture, you can use the [to_datetime](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) function. When passed a `Series`, this returns a `Series` (with the same index), while a list-like is converted to a `DatetimeIndex`:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first look at the **Series** created with a brief list of dates. "
      ],
      "metadata": {
        "id": "lSW1GYOkCRuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.Series(['Jul 31, 2021', 'October 31, 2022', '2022-12-10', None]))"
      ],
      "metadata": {
        "id": "usOH7WzRCc41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can pass that same **Series** to the `.to_datetime()` method to create a **datetime** series."
      ],
      "metadata": {
        "id": "JTOGHMkJC9Ee"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCaT910HjrPn"
      },
      "source": [
        "pd.to_datetime(pd.Series(['Jul 31, 2021', 'October 31, 2022', '2022-12-10', None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XDuDanIlYOQ"
      },
      "source": [
        "In the **datetime** series above, `NaT` represents missing values of **datetime** type.\n",
        "\n",
        "The `.to_datetime()` method converts dates according to `yyyy-mm-dd` format independently of the input with the exception that missing data is recorded as `NaT`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42YI4e8HlZGn"
      },
      "source": [
        "pd.to_datetime(['2005/11/23', '2010.12.31', 'Jul 31, 2021', 'October 31, 2022', '2022-12-10', None])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgHBqaMLlbn-"
      },
      "source": [
        "If you use dates which start with the day first (i.e. European style), you can pass the `dayfirst` flag:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kfEfSMole24"
      },
      "source": [
        "pd.to_datetime(['04-01-2012 10:00', '14-01-2012', '01-14-2012'], dayfirst=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6KqiDnIlilP"
      },
      "source": [
        "You can see in the above example that the `dayfirst` flag is not strict, so if a date canâ€™t be parsed with the day being first it will be parsed as if `dayfirst` were `False`.\n",
        "\n",
        "If you pass a single string to `to_datetime`, it returns a single [Timestamp](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.time.html?highlight=time%20stamp).  `Timestamp` can accept string input. Note that `Timestamp` does not accept string parsing options such as `dayfirst` or `format`, use `to_datetime` if these are required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUguGdjVl7A_"
      },
      "source": [
        "pd.to_datetime('2013/09/23')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h3><b><u>`.to_datetime()` Parameters</b></u></h3></center> \n",
        "\n",
        "<b>Syntax:</b>    \n",
        "    \n",
        "<b>pandas.to_datetime</b>(arg, **errors**=â€™raiseâ€™, **dayfirst**=False, **yearfirst**=False, **utc**=None, **format**=None, **exact**=True, **unit**=None, **infer_datetime_format**=False, **origin**=â€™unixâ€™, **cache**=False)\n",
        "    \n",
        "<b>Arguments:</b>    \n",
        "  - <b><u>arg</b></u>: An integer, string, float, list or dict object to convert in to Date time object.    \n",
        "  - **errors**{`ignore`, `raise`, `coerce`}, default `raise`;    \n",
        "    - If `raise`, then invalid parsing will raise an exception,    \n",
        "    - If `coerce`, then invalid parsing will be set as `NaT`, or    \n",
        "    - If `ignore`, then invalid parsing will return the input.    \n",
        "  - <b><u>dayfirst</b></u>: Boolean value, places day first if True.    \n",
        "  - <b><u>yearfirst</b></u>: Boolean value, places year first if True.    \n",
        "  - <b><u>utc</b></u>: Boolean value, Returns aware time in UTC if True.  Controls timezone-related parsing, localization and conversion.    \n",
        "    - If `True`, the function always returns a timezone-aware UTC-localized Timestamp, Series or DatetimeIndex. To do this, timezone-naive inputs are localized as UTC, while timezone-aware inputs are converted to UTC.    \n",
        "    - If `False` (default), inputs will not be coerced to UTC. Timezone-naive inputs will remain naive, while timezone-aware ones will keep their time offsets. Limitations exist for mixed offsets (typically, daylight savings), see Examples section for details.    \n",
        "  - <b><u>format</b></u>: The `strftime` to parse time, e.g. `\"%d/%m/%Y\"`. Note that `\"%f\"` will parse all the way up to nanoseconds. See [strftime documentation](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior) for more information on choices.    \n",
        "  - <b><u>exact</b></u>: Boolean value. Controls how format is used:    \n",
        "    - If `True`, require an exact format match.    \n",
        "    - If `False`, allow the format to match anywhere in the target string.        \n",
        "  - <b><u>unit</b></u>: The unit of the arg (`D,s,ms,us,ns`) denote the unit, which is an integer or float number. This will be based off the origin. Example, with `unit='ms'` and `origin='unix'`, this would calculate the number of milliseconds to the unix epoch start.    \n",
        "  - <b><u>infer_datetime_format</b></u>: Boolean value, ... if True.    \n",
        "  - <b><u>origin</b></u>: The reference (origin) date.  The numeric values would be parsed as number of units (defined by unit) since this reference date.    \n",
        "    - If `unix` (or `POSIX`) time; origin is set to 1970-01-01.    \n",
        "    - If `julian`, unit must be 'D', and origin is set to beginning of Julian Calendar. Julian day number 0 is assigned to the day starting at noon on `January 1, 4713 BC`.    \n",
        "    - If `Timestamp` convertible, origin is set to `Timestamp` identified by origin. \n",
        "  - <b><u>cache</b></u>: Boolean value, default is `True`. If `True`, use a cache of unique, converted dates to apply the datetime conversion. May produce significant speed-up when parsing duplicate date strings, especially ones with timezone offsets. The cache is only used when there are at least 50 values. The presence of out-of-bounds values will render the cache unusable and may slow down parsing.    \n",
        "   \n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "2Td2C6vmD594"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "11DXbx64sG8j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFbckhhRl-Gn"
      },
      "source": [
        "##3. \"Daily minimum temperatures in Melbourne\" dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SFnZHVImA6u"
      },
      "source": [
        "We're going to be looking some Daily minimum temperatures in Melbourne data from [DataMarket](https://en.wikipedia.org/wiki/DataMarket). This dataset is a list of days and daily minimum temperatures. You can see the data set [here](https://github.com/ef2020/TextFiles/blob/master/daily-minimum-temperatures-in-melbourne.csv). To download the dataset use the `raw` version of the file.  By default, it assumes that the fields are comma-separated. We will use it for reading the dataset file (we called it as \"daily-minimum-temperatures-in-melbourne.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdW5EA4un9so"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/ef2020/TextFiles/master/daily-minimum-temperatures-in-melbourne.csv -o daily-minimum-temperatures-in-melbourne.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2dS9U8ZoGKW"
      },
      "source": [
        "melbourne_temp = pd.read_csv(\"daily-minimum-temperatures-in-melbourne.csv\", \n",
        "                             skiprows=1,  # Allows to skip the header\n",
        "                             names=[\"date\", \"temp\"])  # Let's name columns in such way\n",
        "melbourne_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyAfILUeoI8u"
      },
      "source": [
        "Let's look at columns' types using `dtypes` method. Pay attention to the dataype for the date attribute. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tylKAaUooMEe"
      },
      "source": [
        "melbourne_temp.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4KliV_MuZrq"
      },
      "source": [
        "Let us visualize the data we have. In the previous example we read data and got an Object type. \n",
        "\n",
        "To plot the data we have to convert the column \"temp\" to numeric using the `to_numeric` function. By doing this we change type to `float64` and we can use pyplot to visualize our dataset. We also should to apply the `to_datetime` function to the \"date\" column. It will allow using its values in filters (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4r0a-mFYJuV"
      },
      "source": [
        "melbourne_temp['date'] = pd.to_datetime(melbourne_temp['date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSj0SZZoYNzZ"
      },
      "source": [
        "melbourne_temp.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melbourne_temp.dtypes"
      ],
      "metadata": {
        "id": "oKD8tco6Oq4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMmvApYOYVLh"
      },
      "source": [
        "melbourne_temp.set_index('date', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eUizwCWYX3p"
      },
      "source": [
        "melbourne_temp.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute this housekeeping if you have not already run it\n",
        "# Import matplotlib library\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams"
      ],
      "metadata": {
        "id": "-w3rcbIjJA0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EOhsSL0vQ7a"
      },
      "source": [
        "# Let's change the size of figure drown by matplotlob. figsize represents width & height tuple in inches\n",
        "rcParams['figure.figsize'] = (16, 6)\n",
        "\n",
        "# Convert \"date\" column\n",
        "#melbourne_temp['date'] = pd.to_datetime(melbourne_temp['date'])\n",
        "# Let's convert data to numeric so we can plot it\n",
        "#melbourne_temp['temp'] = pd.to_numeric(melbourne_temp['temp'])\n",
        "\n",
        "#melbourne_temp.set_index('date', inplace=True)\n",
        "\n",
        "# Let's look at type of \"temp\" column\n",
        "print(\"Type of 'temp' column:\", melbourne_temp[\"temp\"].dtypes)\n",
        "melbourne_temp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ4Zpph-vZgY"
      },
      "source": [
        "Now we can see how the considering time series for temperature in Melbourne looks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21GVttkGvcpR"
      },
      "source": [
        "melbourne_temp.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaX4vDP3vgBp"
      },
      "source": [
        "Pay attention that date labels were displayed automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3-EEVrv0sBFS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K_SMkDQvhqY"
      },
      "source": [
        "##4. **Time series** data wrangling\n",
        "\n",
        "Time series data wrangling or manipulation of the data can help develop an idea of the distribution and spread of values.\n",
        "\n",
        "This may help with ideas of data scaling and even data cleaning that can later be performed as part of preparing the dataset for modeling.\n",
        "\n",
        "First of all let's find the minimum temperature for all the time by specifing data and calling `min()` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9GL_1hovpWs"
      },
      "source": [
        "melbourne_temp.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKSzv7dtvtgT"
      },
      "source": [
        "It is possible to select a specific time range defining the respecive year or month like this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNXA6JuJvwKO"
      },
      "source": [
        "melbourne_temp['1981-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdtFbfF0v1V-"
      },
      "source": [
        "or even date between some dates (recall list slicing from CST 1101)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK3optePv6Tv"
      },
      "source": [
        "melbourne_temp['1990-01-05':'1990-01-12']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYC3HEIv9ej"
      },
      "source": [
        "Thus we can build a plot for some sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o48IJxoGv_Ri"
      },
      "source": [
        "melbourne_temp['1981-02'].plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOBLWxSbwDoq"
      },
      "source": [
        "and apply any functions including statistical, for example, let's calculate the average temperature for the above plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OuPOIkWwFh5"
      },
      "source": [
        "melbourne_temp['1981-02'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1d_sZQVwHou"
      },
      "source": [
        "And finally, we count the number of dates where temperature was less then 2 degrees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl5nKIBvwJ7B"
      },
      "source": [
        "print(\"Days with temperature less than 2 degrees:\", (melbourne_temp < 2).sum().values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_jYdNpLQr-iN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu4qOn5_wQrS"
      },
      "source": [
        "##5. Resampling **time series** data   \n",
        "\n",
        "Resampling involves changing the frequency of your time series observations.\n",
        "\n",
        "Two types of resampling are:\n",
        "\n",
        "* **Upsampling**: Where you increase the frequency of the samples, such as from minutes to seconds.\n",
        "* **Downsampling**: Where you decrease the frequency of the samples, such as from days to months.\n",
        "\n",
        "There are perhaps two main reasons why you may be interested in resampling your time series data:\n",
        "\n",
        "* **Problem Framing**: Resampling may be required if your data is available at the same frequency that you want to make predictions.\n",
        "* **Feature Engineering**: Resampling can also be used to provide additional structure or insight into the learning problem for supervised learning models.\n",
        "Letâ€™s make resampling more concrete by looking at a real dataset and some examples.\n",
        "\n",
        "We will use previous dataset \"Daily minimum temperatures in Melbourne, Australia, 1981-1990\"\n",
        "\n",
        "Imagine that we want average weekly temparature information. In this case we have to unsample the information from daily to weekly.\n",
        "\n",
        "We can use this function to transform our daily dataset into a weekly dataset by calling resampling and specifying the preferred frequency of calendar week frequency or \"W\"."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Time Series Frequency for `.resample()` Periodicity**   "
      ],
      "metadata": {
        "id": "Ez_0HoxNt3tE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><u>Most commonly used time series frequency are</b></u>:     \n",
        " - <b><u>W</b></u>:  weekly frequency    \n",
        " - <b><u>M</b></u>:  month end frequency    \n",
        " - <b><u>SM</b></u>:  semi-month end frequency (15th and end of month)    \n",
        " - <b><u>Q</b></u>:  quarter end frequency    \n",
        "\n",
        "<b><u>The full list of Pandas `DateTime` frequency codes that can be used as `.resample()` rules</b></u>\n",
        "\n",
        " - <b><u>B</b></u>:  business day frequency    \n",
        " - <b><u>C</b></u>:  custom business day frequency    \n",
        " - <b><u>D</b></u>:  calendar day frequency    \n",
        " - <b><u>W</b></u>:  weekly frequency    \n",
        " - <b><u>M</b></u>:  month end frequency    \n",
        " - <b><u>SM</b></u>:  semi-month end frequency (15th and end of month)    \n",
        " - <b><u>BM</b></u>:  business month end frequency    \n",
        " - <b><u>CBM</b></u>:  custom business month end frequency    \n",
        " - <b><u>MS</b></u>:  month start frequency   \n",
        " - <b><u>SMS</b></u>:  semi-month start frequency (1st and 15th)    \n",
        " - <b><u>BMS</b></u>:  business month start frequency    \n",
        " - <b><u>CBMS</b></u>:  custom business month start frequency    \n",
        " - <b><u>Q</b></u>:  quarter end frequency    \n",
        " - <b><u>BQ</b></u>:  business quarter end frequency    \n",
        " - <b><u>QS</b></u>:  quarter start frequency    \n",
        " - <b><u>BQS</b></u>:  business quarter start frequency    \n",
        " - <b><u>A, Y</b></u>:  year end frequency    \n",
        " - <b><u>BA, BY</b></u>:  business year end frequency    \n",
        " - <b><u>AS, YS</b></u>:  year start frequency    \n",
        " - <b><u>BAS, BYS</b></u>:  business year start frequency    \n",
        " - <b><u>BH</b></u>:  business hour frequency    \n",
        " - <b><u>H</b></u>:  hourly frequency    \n",
        " - <b><u>T, min</b></u>:  minutely frequency    \n",
        " - <b><u>S</b></u>:  secondly frequency    \n",
        " - <b><u>L, ms</b></u>:  milliseconds    \n",
        " - <b><u>U, us</b></u>:  microseconds    \n",
        " - <b><u>N</b></u>:  nanoseconds    \n"
      ],
      "metadata": {
        "id": "JWOFxRzRSu3S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY6IWErfwhLL"
      },
      "source": [
        "melbourne_temp.resample('W').mean().head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCKzJQDtxN64"
      },
      "source": [
        "Check yourself that in the \"temp\" is realy average temperature for respective week.\n",
        "\n",
        "Instead of creating new rows between existing observations, the [resample()](https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html) function in pandas will group all observations by the new frequency.\n",
        "\n",
        "This operation is called *downsampling*.\n",
        "\n",
        "We can downsample the data using the alias \"A\" for year-end frequency and this time use `min` to calculate the miminum (or `max` for maximum, everything you need) temperature of each year."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hePbipJxrgO"
      },
      "source": [
        "melbourne_temp.resample('A').min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbz3Pv31xuAk"
      },
      "source": [
        "Resampling is also a fast way to smooth in some essence the time series. For instance, the time series of monthly averages has much less peaks or outliers and allows tracking the periodicity.\n",
        "\n",
        "Much accurate way to smooth a time series is the cacluation of rolling average that is the average value of the current point and N previous points. It can be calcualted using [rolling](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html?highlight=rolling#pandas.DataFrame.rolling) pandas's method where we should define the window, i.e. amount of points for average calculation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ohi-nGmb3Hzw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8kylQKwEX6U"
      },
      "source": [
        "##6. **Time series** Rolling Average (Moving Average, Running Average)\n",
        "\n",
        "(https://en.wikipedia.org/wiki/Moving_average)\n",
        "\n",
        "In statistics, a moving average (rolling average or running average) is a calculation to analyze data points by creating a series of averages of different subsets of the full data set. It is also called a moving mean (MM) or rolling mean and is a type of finite impulse response filter. Variations include: simple, cumulative, or weighted forms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxvTr9IuFLuT"
      },
      "source": [
        "Rolling Average is an example of a smoothing technique which is applied to time series to remove the fine-grained variation between time steps. (https://machinelearningmastery.com/moving-average-smoothing-for-time-series-forecasting-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xlXGwKjx7K_"
      },
      "source": [
        "# Draw initial time series and make it transparent\n",
        "ax = melbourne_temp.plot(alpha=0.25)\n",
        "# Draw montly average values\n",
        "melbourne_temp.resample('M').mean().plot(ax=ax)\n",
        "# Draw roling average that takes into account 25 points\n",
        "melbourne_temp.rolling(10).mean().plot(ax=ax)\n",
        "# Specify legend labels\n",
        "ax.legend([\"daily data\", \"montly average\", \"roling mean\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk-jGFP3x-5e"
      },
      "source": [
        "If you set the hourly frequency in the `resample()` function, then NaN values will be created, because there are no more tiny distribution of the temperature.\n",
        "\n",
        "This procedure is called *upsampling*. Before you run this procedure, think if we have the temperature values for every hour. \n",
        "\n",
        "What do you expect to see? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "829yq3lgyECI"
      },
      "source": [
        "upsampled = melbourne_temp.resample('H').mean()\n",
        "upsampled.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjkdxM5iyG_Q"
      },
      "source": [
        "But we can [interpolate](https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html) the missing values at this new frequency.\n",
        "\n",
        "The Series pandas's object provides the interpolate function to interpolate missing values. A good starting point is to use a `linear interpolation`. This draws a straight line between available data and fills in values at the chosen frequency from this line."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upsampled.head(30)"
      ],
      "metadata": {
        "id": "8OIED4nqUcmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmRlWf3QymHR"
      },
      "source": [
        "interpolated = upsampled.interpolate(method='linear')\n",
        "interpolated.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YVpiIhkQq1yE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kirCEWeKAJn5"
      },
      "source": [
        "##7. Exercise: **Time Series** and Forecasting\n",
        "\n",
        "Based on the book Introduction to Time Series and Forecasting by Brockwell and Davis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erIybKUxARwr"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4yfnhrEAUf8"
      },
      "source": [
        "# This is just to select the style of the generated plots. Feel free to experiment\n",
        "# and select other styles that you may like better. Notice that Style sheets are \n",
        "# designed to be composed together. So you can have a style sheet that customizes \n",
        "# colors and a separate style sheet that alters element sizes for presentations. \n",
        "# print(plt.style.available)\n",
        "matplotlib.style.use(['seaborn-talk', 'seaborn-ticks', 'seaborn-whitegrid'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Qw0tnb1FtQ8K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFbwlzIxAWRM"
      },
      "source": [
        "### 7.a Australian red wine \"sales\", (thousands of litres) monthly, Jan 80 - Oct 91"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEFv_zcxAZzm"
      },
      "source": [
        "The file `AusWineSales.csv` contains the monthly sales of Australian red wines in for the period Jan-1980 to Oct-1991. Let us take a peak at the [data file](https://raw.githubusercontent.com/rajansharm/Time-Series-Analysis/master/AusWineSales.csv).\n",
        "\n",
        "Additional Time Series Analysis of the Australian Wines data set can be found [here](https://github.com/rajansharm/Time-Series-Analysis/blob/master/Rajan_TimeSeries.ipynb). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXmK9d5vApxE"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/rajansharm/Time-Series-Analysis/master/AusWineSales.csv -o AusWineSales.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxUM4KtgAyde"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/rajansharm/Time-Series-Analysis/master/AusWineSales.csv\")  # if you use this line, you do not \n",
        "                                                                                                               # need the above cell with !curl\n",
        "#df = pd.read_csv(\"AusWineSales.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xzqSP4WA2uv"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eswd5dLA5WD"
      },
      "source": [
        "Pandas is relatively smart and can infer the data type of a column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcp-47EtA6wQ"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe"
      ],
      "metadata": {
        "id": "mtVTYBv7Wq3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V444KQSJAJ7Z"
      },
      "source": [
        "In this case pandas figured out that Sales is a `number`, but not that Date is an `object`.\n",
        "\n",
        "We can now try to plot directly the contents of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXn1Rz2SBJBP"
      },
      "source": [
        "df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi4VhrH2BNhW"
      },
      "source": [
        "Why do we have a number on the x-axis?\n",
        "\n",
        "The plot would look better if we had the x-axis to be a date, instead of a number. For that, we use the corresponding Pandas functions to convert the columns into the appropriate formats. We also tell Pandas to convert the Date column into the key for each row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoxhrgqVBWw7"
      },
      "source": [
        "df[\"YearMonth\"] = pd.to_datetime(df[\"YearMonth\"])\n",
        "df.set_index(keys=\"YearMonth\", inplace=True)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)"
      ],
      "metadata": {
        "id": "0k_O9yEnXRgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot()"
      ],
      "metadata": {
        "id": "rjLIwDFhXjzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq-8bUWmCYPk"
      },
      "source": [
        "df_Red = df[[\"Red\"]]\n",
        "df_Sparkling = df[[\"Sparkling\"]]\n",
        "df_Sweetwhite = df[[\"Sweetwhite\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qFhzQJhDnH-"
      },
      "source": [
        "df_Red.plot(figsize=(15,7), grid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8kzLSS-DisW"
      },
      "source": [
        "df_Sparkling.plot(figsize=(15,7), grid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8ERGhOIDS7Q"
      },
      "source": [
        "df_Sweetwhite.plot(figsize=(15,7), grid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkX_PwZXDrFl"
      },
      "source": [
        "It appears from the graph that the sales have an upward trend and a seasonal pattern with a peak in July and a trough in January.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8GrqOmxDyZQ"
      },
      "source": [
        "###7.b Jumping Ahead: Lag plots, autocorrelation plots, and decompositions.\n",
        "\n",
        "Pandas provides two types of plots that can be used for the analysis of time series: the lag_plot and the autocorrelation_plot. We can also use the seasonal decomposition functionality of statsmodels to separate the time series into a trend, seasonal component, and residual noise. We will go quickly over these for now, mainly for demo purposes. Proper treatment of these topics require deeper analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omQSCoXxD3Zp"
      },
      "source": [
        "####7.b1 Lag plot\n",
        "\n",
        "The lag plot shows the value of the series at time $t$ vs. its value at time $t+1$. If there is no dependency (i.e., the time series is noise) then the lag plot is a scatterplot without any sign of correlation. If we can see a pattern and a correlation, then the series exhibits autocorrelation. For example, below we can see that there is a rather strong correlation of the two variables, indicating that the sales in time $t+1$ is similar to the sales at time $t$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HhOODBqD-YE"
      },
      "source": [
        "from pandas.plotting import lag_plot\n",
        "lag_plot(df_Red[\"Red\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqaNdYpEJ6Q"
      },
      "source": [
        "####7.b2 Autocorrelation Plot\n",
        "In a more general setting, we want to also see if the value of the series at time $t$ is predictive of the value at time $t+n$. Such dependency would indicate that there is autocorrelation in the series. The autocorrelation plot shows the correlation value for various values of $n$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RE6YFq0ENFH"
      },
      "source": [
        "from pandas.plotting import autocorrelation_plot\n",
        "\n",
        "autocorrelation_plot(df_Red[\"Red\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6Avvmwahqv1e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkT-1HQzES7G"
      },
      "source": [
        "###7.c Trend/Seasonal Decomposition\n",
        "\n",
        "Analyze red wine sales by **season**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW36ozPvEVYj"
      },
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# We decompose assumming a 12-month periodicity. \n",
        "# There is a weekly component as well, which we ignore.\n",
        "# We can also specify a multiplicative instead of an additive model\n",
        "# The additive model is Y[t] = T[t] + S[t] + e[t]\n",
        "# The multiplicative model is Y[t] = T[t] * S[t] * e[t]\n",
        "decomposition = seasonal_decompose(df_Red['Red'], model='multiplicative', freq=12)  \n",
        "fig = plt.figure()  \n",
        "fig = decomposition.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmwewbXXEd1T"
      },
      "source": [
        "####7.d Accessing individual components of the decomposition\n",
        "Once we have the decomposed time series model, we can also access the different components.\n",
        "\n",
        "For example, we can get the trend of the time series, after removing the seasonality component:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTk04VO4Egwd"
      },
      "source": [
        "# The outcome is a pandas Series, which is effectively the same as a single column of dataframe\n",
        "decomposition.trend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "papebeQVEiwe"
      },
      "source": [
        "decomposition.trend.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.e What hypothesis can you test using **time series** analysis of wine sales data for Australia?"
      ],
      "metadata": {
        "id": "ghdKs_rgwOgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### enter a list of hypotheses and how you would test them with time series analysis here...\n",
        "###"
      ],
      "metadata": {
        "id": "-2WsQQGAwaP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "V53ocZUYqZPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## APPENDIX: Summary and Additional References    "
      ],
      "metadata": {
        "id": "9DILwnmQ4bBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "See the article [ARIMA for Time Series with Python from MachineLearningMastery](https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/) on the development of analysis and use of the `ARIMA` model for the Melbourne temperature data set. \n",
        "\n",
        "\n",
        "*note: see the following CST3512 notebooks for additional time series material:*    \n",
        "\n",
        "* **[CST3512_TimeSeries_AirPassengers](https://colab.research.google.com/drive/1t2InZbknRMJBmXs0gq0NcEhIuCduD3tq?usp=sharing)**    \n",
        "\n",
        "* **[DataQuest Time Series Energy Tutorial](https://colab.research.google.com/drive/1TIVLt5XQWBpZGwonb3GTByHFo8LTcPL4?usp=sharing)**    \n",
        "\n",
        "\n",
        "As mentioned at the start of this notebook, here is information on a few time series examples in the real world:\n",
        "\n",
        "* [Central England Temperatures 1659-2016](http://clivebest.com/blog/?p=7603)\n",
        "* [U.S. Real GDP Per Capita (1900 â€“ 2017): Current Economy vs Historical Trend Line](https://bfi.uchicago.edu/insight/chart/u-s-real-gdp-per-capita-1900-2017-current-economy-vs-historical-trendline/)\n",
        "* [New York City's overall water consumption](https://www.reddit.com/r/dataisbeautiful/comments/9tzmkp/oc_surprisingly_new_york_citys_overall_water/)\n",
        "\n"
      ],
      "metadata": {
        "id": "FuotMSKxqaEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Eq8LZusUT4Ct"
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "omQSCoXxD3Zp",
        "-oqaNdYpEJ6Q",
        "UkT-1HQzES7G",
        "AmwewbXXEd1T",
        "ghdKs_rgwOgu"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}