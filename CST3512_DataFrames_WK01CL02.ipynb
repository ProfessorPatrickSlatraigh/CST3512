{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CST3512_DataFrames_WK01CL02.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorPatrickSlatraigh/CST3512/blob/main/CST3512_DataFrames_WK01CL02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g05z2njpaeTZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Pandas"
      ],
      "metadata": {
        "id": "4t18D-cQTh2y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycUTUOp0RPLL"
      },
      "source": [
        "## Setup and preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPK-fH_vRPLR"
      },
      "source": [
        "In order to read and process files, we are going to use a very powerful, and widely used Python library, called pandas. So, our next step is to import the pandas library in Python, and also import the library matplotlib for generating plots:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs9khdOxRPLS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZIRsPfkbFRN"
      },
      "source": [
        "# Data Types and Conversions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou04bj1STXa4"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRkwgJ2BRPLl"
      },
      "source": [
        "## From CSV Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YF27gS9RPLl"
      },
      "source": [
        "We will use a dataset with [restaurant inspection results in NYC](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j).\n",
        "\n",
        "We fetch it by executing the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5GO33l5RPLm"
      },
      "source": [
        "# Fetches the most recent dataset\n",
        "!curl 'https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD' -o restaurant.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNsW_56mRPLq"
      },
      "source": [
        "We want to be able to read and process this file within Python. The pandas library has a very convenient method `read_csv` which reads the file, and returns back a variable that contains its contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0_mc9_6RPLq"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "restaurants = pd.read_csv(\n",
        "    \"restaurant.csv\",\n",
        "    encoding=\"utf_8\",\n",
        "    dtype=\"unicode\",\n",
        "    parse_dates=True,\n",
        "    infer_datetime_format=True,\n",
        "    low_memory=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13OxAtwORPLt"
      },
      "source": [
        "When you read a CSV, you get back a kind of object called a DataFrame, which is made up of rows and columns. You get columns out of a DataFrame the same way you get elements out of a dictionary. Let's take a look at how the object looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHawKZ5fRPLu"
      },
      "source": [
        "restaurants.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJyyVRCORPLz"
      },
      "source": [
        "The read_csv method has many options, and you can read further in the [online documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.parsers.read_csv.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-iZUdU_bFRO"
      },
      "source": [
        "We can also check the data types for each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bsnaxMvbFRO"
      },
      "source": [
        "restaurants.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "205YdxR7bFRO"
      },
      "source": [
        "We can use the method \"describe()\" to get a quick overview of the data in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgtjukEUbFRO"
      },
      "source": [
        "restaurants.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqJxEPXRbFRO"
      },
      "source": [
        "# Same as above, but the .T command transposes the table\n",
        "restaurants.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHC1TUZbbFRP"
      },
      "source": [
        "The `object` type is a string. For many of these, we would like to change the data types for a few columns, using the `pd.to_numeric` and `pd.to_datetime` functions. We examine how to convert data types below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8ydX8BvbFRP"
      },
      "source": [
        "### Converting Data Types to Numeric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vgNMzSLbFRP"
      },
      "source": [
        "The `object` type is a string. When we want to convert an object to numeric, we can use the `pd.to_numeric` function, as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-kwPiYgbFRP"
      },
      "source": [
        "restaurants[\"SCORE\"] = pd.to_numeric(restaurants[\"SCORE\"])\n",
        "restaurants[\"Latitude\"] = pd.to_numeric(restaurants[\"Latitude\"])\n",
        "restaurants[\"Longitude\"] = pd.to_numeric(restaurants[\"Longitude\"])\n",
        "restaurants.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUJ3feX4jp3A"
      },
      "source": [
        "###  Converting Data to Dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnWM14k4RPMQ"
      },
      "source": [
        "Now let's convert the dates columns into the appropriate data types. Let's take a look at a few dates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgt0jCuwbFRQ"
      },
      "source": [
        "restaurants[\"GRADE DATE\"] = pd.to_datetime(restaurants[\"GRADE DATE\"])\n",
        "restaurants[\"RECORD DATE\"] = pd.to_datetime(restaurants[\"RECORD DATE\"])\n",
        "restaurants[\"INSPECTION DATE\"] = pd.to_datetime(restaurants[\"INSPECTION DATE\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz57tm7GRPMT"
      },
      "source": [
        "#### Note\n",
        "\n",
        "\n",
        "In tricky cases, we may need to pass the `format` parameter, specifying the formatting of the date. For that, we need to understand first how to [parse dates using the Python conventions](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlxRdtyRbFRQ"
      },
      "source": [
        "### Converting Data to Categorical Variables\n",
        "\n",
        "This is less important, but sometimes we want to specify variables to be \"Categorical\". This is most commonly useful when we have variables that have an implicit order (e.g., the A/B/C grade of the restaurant)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSsdFQCFbFRR"
      },
      "source": [
        "restaurants[\"BORO\"] = pd.Categorical(restaurants[\"BORO\"], ordered=False)\n",
        "restaurants[\"GRADE\"] = pd.Categorical(\n",
        "    restaurants[\"GRADE\"], categories=[\"A\", \"B\", \"C\"], ordered=True\n",
        ")\n",
        "restaurants[\"VIOLATION CODE\"] = pd.Categorical(\n",
        "    restaurants[\"VIOLATION CODE\"], ordered=False\n",
        ")\n",
        "restaurants[\"CRITICAL FLAG\"] = pd.Categorical(\n",
        "    restaurants[\"CRITICAL FLAG\"], ordered=False\n",
        ")\n",
        "restaurants[\"ACTION\"] = pd.Categorical(restaurants[\"ACTION\"], ordered=False)\n",
        "restaurants[\"CUISINE DESCRIPTION\"] = pd.Categorical(\n",
        "    restaurants[\"CUISINE DESCRIPTION\"], ordered=False\n",
        ")\n",
        "\n",
        "restaurants[\"INSPECTION TYPE\"] = pd.Categorical(\n",
        "    restaurants[\"INSPECTION TYPE\"], ordered=False\n",
        ")\n",
        "\n",
        "restaurants.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XOmLIFibTMj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nLcGpcDRPLz"
      },
      "source": [
        "## Descriptive statistics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AIX3fGLRPL7"
      },
      "source": [
        "### Descriptive Statistics for Numeric Variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_44IGXw4RPL_"
      },
      "source": [
        "#### Basic descriptive statistics for numeric variables\n",
        "\n",
        "Given that SCORE is a numeric variable, we can get more detailed descriptive statistics for the variable using the `.describe()` command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91cmXd7FRPL_"
      },
      "source": [
        "restaurants[\"SCORE\"].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vcYE-MURPMP"
      },
      "source": [
        "### Descriptive Statistics for Dates\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXvztpgJRPMb"
      },
      "source": [
        "restaurants[[\"INSPECTION DATE\", \"GRADE DATE\", \"RECORD DATE\"]].describe(datetime_is_numeric=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr13GaTubFRV"
      },
      "source": [
        "restaurants[\"INSPECTION DATE\"].describe(datetime_is_numeric=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVqJmxWcbFRV"
      },
      "source": [
        "restaurants[\"GRADE DATE\"].describe(datetime_is_numeric=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Zxt8zQbFRW"
      },
      "source": [
        "restaurants[\"RECORD DATE\"].describe(datetime_is_numeric=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsAgjwRyRPM7"
      },
      "source": [
        "### Descriptive Statistics for Categorical/string columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRaEBS-GRPM7"
      },
      "source": [
        "We can also get quick statistics about the common values that appear in each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iZZ5ERvRPM8"
      },
      "source": [
        "restaurants[\"DBA\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syGbdu-9RPM-"
      },
      "source": [
        "restaurants[\"CUISINE DESCRIPTION\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbvxeiqrTKJV"
      },
      "source": [
        "# Basic Data Manipulation Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTKmk7LqRPOC"
      },
      "source": [
        "## Selecting a subset of the columns -- `filter()`\n",
        "\n",
        "In a dataframe, we can specify the column(s) that we want to keep, and get back another dataframe with just the subset of the columns that we want to keep.\n",
        "[`filter()` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.filter.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdGNyALJRPOD"
      },
      "source": [
        "restaurants"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoA5JqtFRPOF"
      },
      "source": [
        "restaurants.filter( \n",
        "    items = [\"DBA\", \"GRADE\", \"GRADE DATE\"] \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DbB0h26RPON"
      },
      "source": [
        "columns = [\"GRADE DATE\", \"VIOLATION CODE\", \"DBA\", \"SCORE\"]\n",
        "\n",
        "# Notice the use of \"chain notation\" below\n",
        "# Chain notation means putting parentheses around\n",
        "# the command and then having each operation in its\n",
        "# own line\n",
        "(\n",
        "  restaurants\n",
        "  .filter( items = columns )\n",
        "  .head(10)\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNmPSBrJUrfy"
      },
      "source": [
        "We can also use the `like` option to find all the column names that include a certain string. For example, to get all the columns that include the string `DATE`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0skTt0rNRPOP"
      },
      "source": [
        "restaurants.filter(\n",
        "    like = 'DATE'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXTR3gaYU3D9"
      },
      "source": [
        "We can expand the functionality and also use regular expressions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE5G-RtCU9NS"
      },
      "source": [
        "restaurants.filter(\n",
        "    regex = r'^C' # all the columns that start with C\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWg63of5xbjY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHIvI4svxcJ0"
      },
      "source": [
        "## Renaming Columns -- `rename()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fLRqM4kxf1W"
      },
      "source": [
        "To do the equivalent of `SELECT attr AS alias` in Pandas, we use the `rename` command, and pass a dictionary specifying which columns we want to rename:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSnqzBFwxqnk"
      },
      "source": [
        "restaurants.rename(\n",
        "    columns = {\n",
        "      \"CAMIS\": \"RESTID\",\n",
        "      \"DBA\": \"REST_NAME\",\n",
        "      \"BUILDING\": \"STREET_NUM\",\n",
        "      \"BORO\": \"BOROUGH\"\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcirVVhaRPOR"
      },
      "source": [
        "## Selecting rows -- `query()`\n",
        "\n",
        "To select rows, we can use the following approach, where we generate a list of boolean values, one for each row of the dataframe, and then we use the list to select which of the rows of the dataframe we want to keep\"\n",
        "\n",
        "[`query` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_u2KIdGXav3"
      },
      "source": [
        "# Find all violations for restaurants with DBA being Starbucks\n",
        "restaurants.query(' DBA == \"STARBUCKS\" ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37-qYFVyRPOT"
      },
      "source": [
        "# Find all violations with code 04L (i.e., \"has mice\")\n",
        "# Notice the use of backquotes for attribute names that have space\n",
        "restaurants.query(' `VIOLATION CODE` == \"04L\" ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V106ezm-RPOW"
      },
      "source": [
        "# We can store the result in a dataframe called  has_mice\n",
        "has_mice = restaurants.query(' `VIOLATION CODE` == \"04L\" ')\n",
        "has_mice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXC7DeISRPOa"
      },
      "source": [
        "# The most frequent DBA names overall\n",
        "restaurants[\"DBA\"].value_counts()[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieEWvEbZRPOf"
      },
      "source": [
        "# List the most frequent DBA values in the dataframe\n",
        "has_mice[\"DBA\"].value_counts()[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eag5DaYgRPOh"
      },
      "source": [
        "has_mice[\"CAMIS\"].value_counts()[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POUKSEmsRPOj"
      },
      "source": [
        "has_mice.query( ' CAMIS == \"50015263\" ' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaIVZ16DRPOn"
      },
      "source": [
        "And we can use more complex conditions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j2_O5AdRPOn"
      },
      "source": [
        "# AND in pandas is \"&\"\n",
        "# OR in pandas is \"|\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBDoVR50RPOo"
      },
      "source": [
        "has_mice_10012 = (\n",
        "    restaurants\n",
        "    .query(' `VIOLATION CODE` == \"04L\" & ZIPCODE == \"10012\" ')\n",
        "    .filter( items = ['DBA', 'BUILDING', 'STREET', 'INSPECTION DATE'])\n",
        ")\n",
        "\n",
        "has_mice_10012"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLEmEPIRRPOr"
      },
      "source": [
        "has_mice_10012[\"DBA\"].value_counts()[:30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3NvGsgoRPOs"
      },
      "source": [
        "has_mice_10012[\"DBA\"].value_counts()[30::-1].plot(kind=\"barh\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07cNAS0Lcf_y"
      },
      "source": [
        "## Selecting distinct values -- `drop_duplicates()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii2uPjjydLyD"
      },
      "source": [
        "We can do the equivalent of `SELECT DISTINCT` in Pandas by doing the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmHYLEwhdMei"
      },
      "source": [
        "(\n",
        "    has_mice_10012\n",
        "    .filter( items = ['DBA', 'BUILDING', 'STREET'])\n",
        "    .drop_duplicates()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eqOEGYXdl6K"
      },
      "source": [
        "## Sorting values -- `sort_values()`\n",
        "\n",
        "And we can do the equivalent of `ORDER BY` by using the `.sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vImT3bKGdz1_"
      },
      "source": [
        "(\n",
        "    has_mice_10012\n",
        "    .sort_values(\"INSPECTION DATE\", ascending=False)\n",
        "    .head(15)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa78sxUEeev3"
      },
      "source": [
        "(\n",
        "    has_mice_10012\n",
        "    .sort_values([\"INSPECTION DATE\",\"DBA\"], ascending=[False,True])\n",
        "    .head(15)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV9NGwc2bUCS"
      },
      "source": [
        "## Defining New Columns -- `assign()` and `apply()`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdiZXyXIq4rx"
      },
      "source": [
        "### Using the `assign()` approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlTXmZwqkcSE"
      },
      "source": [
        "The `assign` command applies a function to a dataframe and returns back a new dataframe with the new column(s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtL_mCUpbbjd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# We define a function that will take as input a dataframe df\n",
        "# and returns back a new column. This function computes\n",
        "# the distance (in miles) from CityTech, given the lat/lon of the \n",
        "# other location\n",
        "def distance(df):\n",
        "  CityTech_lon = -73.9861\n",
        "  CityTech_lat = 40.6973\n",
        "  # The calculation below is simply the Pythagorean theorem.\n",
        "  # The normalizing values are just for converting lat/lon differences\n",
        "  # to miles\n",
        "  distance = ((df.Latitude-CityTech_lat)/0.0146)**2 + ((df.Longitude-CityTech_lon)/0.0196)**2\n",
        "  return np.sqrt(distance)\n",
        "\n",
        "# This function combines STREET/BUILDING/BORO/ZIPCODE columns into one address\n",
        "def combine_address(df):\n",
        "  return (df.BUILDING + ' ' + df.STREET + ', '  + df.ZIPCODE).str.upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqr1oIJYczP3"
      },
      "source": [
        "# We now use the `assign` function to create two new columns\n",
        "# using the logic in the functions above,\n",
        "(\n",
        "  restaurants\n",
        "  .assign(\n",
        "      distance_from_CityTech = distance,\n",
        "      address = combine_address\n",
        "  )\n",
        "  .filter(items = ['DBA','address','distance_from_CityTech'])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ub8-qFWixeb"
      },
      "source": [
        "# And let's eliminate now duplicates and sort by distance\n",
        "(\n",
        "  restaurants\n",
        "  .assign(\n",
        "      distance_from_CityTech = distance,\n",
        "      address = combine_address\n",
        "  )\n",
        "  .filter(items = ['DBA','address','distance_from_CityTech'])\n",
        "  .query('distance_from_CityTech > 0') # eliminates NaN values from distance_from_CityTech\n",
        "  .drop_duplicates()\n",
        "  .sort_values('distance_from_CityTech')\n",
        "  .head(20)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgr0Yg_3k6qW"
      },
      "source": [
        "### Using the `apply` approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njW0EhjzmyK6"
      },
      "source": [
        "The `apply` function allow the users to pass a function and apply it on every single row or column of a Pandas datarame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIZ_H-s6db9e"
      },
      "source": [
        "!sudo pip3 install -q -U geopy\n",
        "\n",
        "from geopy import distance\n",
        "\n",
        "# A bit more accurate distance calculation, which returns back\n",
        "# the distance in miles. However, we cannot pass a dataframe\n",
        "# to the function but only individual values\n",
        "def distance_from_CityTech_geodesic(row):\n",
        "  CityTech_lon = -73.9861\n",
        "  CityTech_lat = 40.6973\n",
        "  CityTech = (CityTech_lat, CityTech_lon)\n",
        "  rest = (row.Latitude, row.Longitude)\n",
        "  #if pd.isnull(row.Latitude) or pd.isnull(row.Longitude):\n",
        "  #  return None\n",
        "  return distance.distance(CityTech, rest).miles\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71KKNBOqlBTp"
      },
      "source": [
        "# We now create a smaller version of the dataset with just\n",
        "# the names/address/lon/lat of the restaurants\n",
        "rest_names_locations = (\n",
        "    restaurants\n",
        "    .assign(\n",
        "      address = combine_address\n",
        "    )\n",
        "    .filter(items = ['CAMIS','DBA','address','Longitude', 'Latitude'])\n",
        "    .query(' Longitude==Longitude ') # idiomatic expression for saying IS NOT NULL\n",
        "    .query(' Latitude==Latitude ') # idiomatic expression for saying IS NOT NULL\n",
        "    .drop_duplicates()\n",
        ")\n",
        "\n",
        "rest_names_locations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q0gGzxOpE7x"
      },
      "source": [
        "# We will now apply the function distance_from_CityTech_geodesic \n",
        "# to every row of the dataset:\n",
        "rest_names_locations.apply(distance_from_CityTech_geodesic, axis='columns')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82MvcB29pG1z"
      },
      "source": [
        "# We will now save the result into a new column\n",
        "rest_names_locations['distance_from_CityTech']=rest_names_locations.apply(distance_from_CityTech_geodesic, axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6vbuAUfdglf"
      },
      "source": [
        "# Let's see how many restaurants are within half a mile from NYU :)\n",
        "(\n",
        "    rest_names_locations\n",
        "    .query('distance_from_CityTech < 0.5')\n",
        "    .sort_values('distance_from_CityTech')\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54FqcwHSeUM7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTcny4zSw426"
      },
      "source": [
        "## Aggregation Function -- `agg()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUNvMhwNCWF5"
      },
      "source": [
        "restaurants['SCORE'].agg('mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpVaAe2uz8Bk"
      },
      "source": [
        "restaurants['SCORE'].agg(['mean','std','count','nunique'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJP_gFvKzCNY"
      },
      "source": [
        "restaurants.agg(\n",
        "    {\n",
        "        'SCORE': ['mean','std','count','nunique'],\n",
        "        'CAMIS':  ['nunique','count']\n",
        "     }\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92Gsuibr0Zi1"
      },
      "source": [
        "restaurants.agg(\n",
        "        num_scored_violations = ('SCORE', 'count'),\n",
        "        mean_score = ('SCORE', 'mean'),\n",
        "        std_score  = ('SCORE', 'std'),\n",
        "        num_entries = ('CAMIS',  'count'),\n",
        "        num_restaurants = ('CAMIS',  'nunique'),\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDAZWbRxw5JJ"
      },
      "source": [
        "## Calculating aggegates per groups -- `groupby()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtjmJWijDXYU"
      },
      "source": [
        "restaurants.groupby('GRADE DATE').agg({'SCORE': 'mean'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSoefDKZEbMp"
      },
      "source": [
        "(\n",
        "  restaurants\n",
        "  .groupby('GRADE DATE')\n",
        "  .agg(\n",
        "      score_mean = ('SCORE', 'mean'), \n",
        "      graded_restaurants = ('CAMIS', 'nunique')\n",
        "    )\n",
        "  .tail(500)\n",
        "  .head(20)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UR7tKEURPOu"
      },
      "source": [
        "## Pivot Tables\n",
        "\n",
        "[Pivot tables](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html) is one of the most commonly used exploratory tools, and in Pandas they are extremely flexible. \n",
        "\n",
        "For example, let's try to count the number of restaurants that are inspected every day. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5m48HZFRPOu"
      },
      "source": [
        "# Count the number of CAMIS values that appear on each date\n",
        "\n",
        "pivot = pd.pivot_table(\n",
        "    data=restaurants,\n",
        "    index=\"GRADE DATE\",  # specifies the rows\n",
        "    values=\"CAMIS\",  # specifies the content of the cells\n",
        "    aggfunc=\"count\",  # we ask to count how many different CAMIS values we see\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXbdJgt8RPOy"
      },
      "source": [
        "pivot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuzOxstCRPPA"
      },
      "source": [
        "#### Changing date granularity \n",
        "\n",
        "We can also use the [resample](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html) command to change the frequency from one day, to, say, 7 days. Then we can compute, say, the average (`mean()`) for these days, or the total number (`sum()`) of inspections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffCg-Jo-RPPB"
      },
      "source": [
        "pivot.resample(\"1W\").sum().tail(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhabll3RPPL"
      },
      "source": [
        "#### Pivot Table with two (or more) variables)\n",
        "\n",
        "We would like to break down the results by borough, so we add the `column` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x57cwCMARPPM"
      },
      "source": [
        "pivot2 = pd.pivot_table(\n",
        "    data=restaurants,  #\n",
        "    index=\"INSPECTION DATE\",\n",
        "    columns=\"BORO\",\n",
        "    values=\"CAMIS\",\n",
        "    aggfunc=\"count\",\n",
        ")\n",
        "pivot2.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRNJSEEVRPPN"
      },
      "source": [
        "##### Deleting rows and columns\n",
        "\n",
        "Now, you will notice that there are a few columns and rows that are just noise. The first row with date *'1900-01-01'* is clearly noise, and the *'0'* column is also noise. We can use the `drop` command of Pandas to drop these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypaHCyOQRPPN"
      },
      "source": [
        "# The axis='index' (or axis=0) means that we delete a row with that index value\n",
        "pivot2 = pivot2.drop(pd.to_datetime(\"1900-01-01\"), axis=\"index\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoZ8g0Q_RPPP"
      },
      "source": [
        "# The axis='columns' (or axis=1) means that we delete a columns with that value\n",
        "pivot2 = pivot2.drop(\"0\", axis=\"columns\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScaU_IdYRPPR"
      },
      "source": [
        "pivot2.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS8nDH9DRPPW"
      },
      "source": [
        "## (Optional, FYI) Advanced Pivot Tables\n",
        "\n",
        "We can also add multiple attributes in the index and columns. It is also possible to have multiple aggregation functions, and we can even define our own aggregation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX1uJBmsRPPW"
      },
      "source": [
        "# We write a function that returns the\n",
        "# number of unique items in a list x\n",
        "def count_unique(x):\n",
        "    return len(set(x))\n",
        "\n",
        "\n",
        "# We break down by BORO and GRADE, and also calculate\n",
        "# inspections in unique (unique restaurants)\n",
        "# and non-unique entries (effectuvely, violations)\n",
        "pivot_advanced = pd.pivot_table(\n",
        "    data=restaurants,  #\n",
        "    index=\"GRADE DATE\",\n",
        "    columns=[\"BORO\", \"GRADE\"],\n",
        "    values=\"CAMIS\",\n",
        "    aggfunc=[\"count\", count_unique],\n",
        ")\n",
        "\n",
        "# Take the total number of inspections (unique and non-unique)\n",
        "agg = pivot_advanced.resample(\"1M\").sum()\n",
        "\n",
        "# Show the last 5 entries and show the transpose (.T)\n",
        "agg.tail().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Voat735yRPPZ"
      },
      "source": [
        "### Exercise 1 \n",
        "\n",
        "Now let's do the same exercise, but instead of counting the number of inspections, we want to compute the average score assigned by the inspectors. Hint: We will need to change the `values` and the `aggfunc` parameters in the `pivot_table` function above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCG1ciIRPPa"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLgKXET5RPPb",
        "solution2": "hidden",
        "solution2_first": true
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As9qTwYLRPPb",
        "solution2": "hidden"
      },
      "source": [
        "pivot = pd.pivot_table(\n",
        "    data=restaurants,\n",
        "    index=\"INSPECTION DATE\",  # specifies the rows\n",
        "    values=\"SCORE\",  # specifies the content of the cells\n",
        "    aggfunc=\"mean\",  # compute the average SCORE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}