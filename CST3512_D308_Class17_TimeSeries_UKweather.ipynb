{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "G8GrqOmxDyZQ",
        "FuotMSKxqaEh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorPatrickSlatraigh/CST3512/blob/main/CST3512_D308_Class17_TimeSeries_UKweather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CST3512 Class 17    \n",
        "\n",
        "**Time Series - UK Weather**    \n",
        "\n",
        "*notebook courtesy of Professor Elena Filatova, CUNY CityTech, 2022*    \n",
        "\n"
      ],
      "metadata": {
        "id": "CBjLkAmeOmyD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6S_bj729qwZ"
      },
      "source": [
        "## What is time series?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t8MRbpE9rq-"
      },
      "source": [
        "Readings:\n",
        "* [Time Series Analysis with Pandas](https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/)\n",
        "* [Brief Tutorial](https://towardsdatascience.com/time-series-analysis-for-beginners-8a200552e332)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWu6YHzdciQy"
      },
      "source": [
        "\n",
        "A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data. A time series can be taken on any variable that changes over time.\n",
        "\n",
        "The usage of time series models is twofold:\n",
        "\n",
        "* Obtain an understanding of the underlying forces and structure that produced the observed data;\n",
        "* Fit a model and proceed to forecasting, monitoring or even feedback and feedforward control.\n",
        "\n",
        "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, intelligent transport and trajectory forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and largely in any domain of applied science and engineering which involves temporal measurements.\n",
        "\n",
        "Time series are very frequently plotted via line charts.\n",
        "\n",
        "Here is information on a few time series examples in the real world:\n",
        "\n",
        "* [Central England Temperatures 1659-2016](http://clivebest.com/blog/?p=7603)\n",
        "* [U.S. Real GDP Per Capita (1900 – 2017): Current Economy vs Historical Trend Line](https://bfi.uchicago.edu/insight/chart/u-s-real-gdp-per-capita-1900-2017-current-economy-vs-historical-trendline/)\n",
        "* [New York City's overall water consumption](https://www.reddit.com/r/dataisbeautiful/comments/9tzmkp/oc_surprisingly_new_york_citys_overall_water/)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "P2j8yws3sLbM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW59byULjJLg"
      },
      "source": [
        "## Working with time series in pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSmclFjLjMaP"
      },
      "source": [
        "Pandas has proven very successful as a tool for working with time series data, especially in the financial data analysis space. Using the [NumPy](https://numpy.org/) `datetime64` and `timedelta64` dtypes, pandas consolidated a large number of features from other Python libraries as well as created a tremendous amount of new functionality for manipulating time series data.\n",
        "\n",
        "In working with time series data, you will frequently seek to:\n",
        "\n",
        "* generate sequences of fixed-frequency dates and time spans\n",
        "* conform or convert time series to a particular frequency\n",
        "* compute \"relative\" dates based on various non-standard time increments (e.g. 5 business days before the last business day of the year) or \"roll\" dates forward or backward\n",
        "\n",
        "The following examples demonstrate how to work with time, date and datetime data using pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdLF3QI4jZc3"
      },
      "source": [
        "First of all, let's generate a list of datetime values for 3 neighboring days starting from 10/01/2021 with the interval equals to one hour. The [date_range](https://pandas.pydata.org/docs/reference/api/pandas.date_range.html?highlight=date_range) function can return such list in [DatetimeIndex](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.strftime.html) format. We simply should define the left bound for generating dates start (\"10/01/2021\" in our case), the right bound for generating dates end or the amount of intervals periods (3*24 in our case, because we are going to cover three days) and preferable frequency freq ('H' in our case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhj1y80Xel3n"
      },
      "source": [
        "# Import pandas library at first\n",
        "import pandas as pd\n",
        "\n",
        "example_range = pd.date_range(start='11/01/2022', periods=3*24, freq='H')\n",
        "print(\"Amount of elements:\", len(example_range.values))\n",
        "example_range[:25]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmhsmBhmjr_X"
      },
      "source": [
        "In the same way we can define any other period in the freq attribute, for example, days. The full list of possible values can be found [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html).\n",
        "\n",
        "Also, we can create time series, that can be manipulated naturally and easily. First step that we have to do is to create the range of dates for our time series (as mentioned above). Record starts at 2021-09-25 and ends at `2021-10-05`. Frequency of the data is one month (`freq='D'`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzrf-v9vj4g2"
      },
      "source": [
        "dates = pd.date_range('2022-09-25', '2022-11-01', freq='D')\n",
        "dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CODxzcJkdag"
      },
      "source": [
        "\n",
        "To convert a `Series` or list-like object of date-like objects e.g. strings, epochs, or a mixture, you can use the [to_datetime](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) function. When passed a Series, this returns a `Series` (with the same index), while a list-like is converted to a DatetimeIndex:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCaT910HjrPn"
      },
      "source": [
        "pd.to_datetime(pd.Series(['Jul 31, 2009', '2010-12-10', None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XDuDanIlYOQ"
      },
      "source": [
        "Above NaT represents missing values of datetime type.\n",
        "\n",
        "It converts date according to yyyy-mm-dd format independently of the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42YI4e8HlZGn"
      },
      "source": [
        "pd.to_datetime(['2005/11/23', '2010.12.31'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgHBqaMLlbn-"
      },
      "source": [
        "If you use dates which start with the day first (i.e. European style), you can pass the `dayfirst` flag:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kfEfSMole24"
      },
      "source": [
        "pd.to_datetime(['04-01-2012 10:00', '14-01-2012', '01-14-2012'], dayfirst=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6KqiDnIlilP"
      },
      "source": [
        "You can see in the above example that dayfirst isn’t strict, so if a date can’t be parsed with the day being first it will be parsed as if dayfirst were False.\n",
        "\n",
        "If you pass a single string to `to_datetime`, it returns single [Timestamp](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.time.html?highlight=time%20stamp). Also, `Timestamp` can accept the string input. Note that `Timestamp` doesn’t accept string parsing option like `dayfirst` or `format`, use `to_datetime` if these are required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUguGdjVl7A_"
      },
      "source": [
        "pd.to_datetime('2013/09/23')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "11DXbx64sG8j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFbckhhRl-Gn"
      },
      "source": [
        "## \"Daily minimum temperatures in Melbourne\" dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SFnZHVImA6u"
      },
      "source": [
        "We're going to be looking some Daily minimum temperatures in Melbourne data from [DataMarket](https://en.wikipedia.org/wiki/DataMarket). This dataset is a list of days and daily minimum temperatures. You can see the data set [here](https://github.com/ef2020/TextFiles/blob/master/daily-minimum-temperatures-in-melbourne.csv). To download the dataset use the `raw` version of the file.  By default, it assumes that the fields are comma-separated. We will use it for reading the dataset file (we called it as \"daily-minimum-temperatures-in-melbourne.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdW5EA4un9so"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/ef2020/TextFiles/master/daily-minimum-temperatures-in-melbourne.csv -o daily-minimum-temperatures-in-melbourne.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2dS9U8ZoGKW"
      },
      "source": [
        "melbourne_temp = pd.read_csv(\"daily-minimum-temperatures-in-melbourne.csv\", \n",
        "                             skiprows=1,  # Allows to skip the header\n",
        "                             names=[\"date\", \"temp\"])  # Let's name columns in such way\n",
        "melbourne_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyAfILUeoI8u"
      },
      "source": [
        "Let's look at columns' types using `dtypes` method. Pay attention to the dataype for the date attribute. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tylKAaUooMEe"
      },
      "source": [
        "melbourne_temp.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4KliV_MuZrq"
      },
      "source": [
        "Let us visualize the data we have. In the previous example we read data and got an Object type. \n",
        "\n",
        "To plot the data we have to convert the column \"temp\" to numeric using the `to_numeric` function. By doing this we change type to `float64` and we can use pyplot to visualize our dataset. We also should to apply the `to_datetime` function to the \"date\" column. It will allow using its values in filters (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4r0a-mFYJuV"
      },
      "source": [
        "melbourne_temp['date'] = pd.to_datetime(melbourne_temp['date'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSj0SZZoYNzZ"
      },
      "source": [
        "melbourne_temp.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melbourne_temp.dtypes"
      ],
      "metadata": {
        "id": "oKD8tco6Oq4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMmvApYOYVLh"
      },
      "source": [
        "melbourne_temp.set_index('date', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eUizwCWYX3p"
      },
      "source": [
        "melbourne_temp.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EOhsSL0vQ7a"
      },
      "source": [
        "# Import matplotlib library at first\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "# Let's change the size of figure drown by matplotlob. figsize represents width & height tuple in inches\n",
        "rcParams['figure.figsize'] = (16, 6)\n",
        "\n",
        "# Convert \"date\" column\n",
        "#melbourne_temp['date'] = pd.to_datetime(melbourne_temp['date'])\n",
        "# Let's convert data to numeric so we can plot it\n",
        "#melbourne_temp['temp'] = pd.to_numeric(melbourne_temp['temp'])\n",
        "\n",
        "#melbourne_temp.set_index('date', inplace=True)\n",
        "\n",
        "# Let's look at type of \"temp\" column\n",
        "print(\"Type of 'temp' column:\", melbourne_temp[\"temp\"].dtypes)\n",
        "melbourne_temp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ4Zpph-vZgY"
      },
      "source": [
        "Now we can see how the considering time series for temperature in Melbourne looks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21GVttkGvcpR"
      },
      "source": [
        "melbourne_temp.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaX4vDP3vgBp"
      },
      "source": [
        "Pay attention that date labels were displayed automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3-EEVrv0sBFS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K_SMkDQvhqY"
      },
      "source": [
        "## Manipulation with data\n",
        "\n",
        "Manipulation with data can help get an idea of the distribution and spread of values.\n",
        "\n",
        "This may help with ideas of data scaling and even data cleaning that you can perform later as part of preparing your dataset for modeling.\n",
        "\n",
        "First of all let's find the minimum temperature for all the time by specifing data and calling `min()` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9GL_1hovpWs"
      },
      "source": [
        "melbourne_temp.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKSzv7dtvtgT"
      },
      "source": [
        "It is possible to select a specific time range defining the respecive year or month like this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNXA6JuJvwKO"
      },
      "source": [
        "melbourne_temp['1981-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdtFbfF0v1V-"
      },
      "source": [
        "or even date between some dates (recall list slicing from CST 1101)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK3optePv6Tv"
      },
      "source": [
        "melbourne_temp['1990-01-05':'1990-01-12']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYC3HEIv9ej"
      },
      "source": [
        "Thus we can build a plot for some sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o48IJxoGv_Ri"
      },
      "source": [
        "melbourne_temp['1981-02'].plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOBLWxSbwDoq"
      },
      "source": [
        "and apply any functions including statistical, for example, let's calculate the average temperature for the above plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OuPOIkWwFh5"
      },
      "source": [
        "melbourne_temp['1981-02'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1d_sZQVwHou"
      },
      "source": [
        "And finally, we count the number of dates where temperature was less then 2 degrees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl5nKIBvwJ7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b352bf-2120-4a4f-c0dd-66bbf3f9babc"
      },
      "source": [
        "print(\"Days with temperature less than 2 degrees:\", (melbourne_temp < 2).sum().values[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Days with temperature less than 2 degrees: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_jYdNpLQr-iN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu4qOn5_wQrS"
      },
      "source": [
        "## Resampling\n",
        "\n",
        "Resampling involves changing the frequency of your time series observations.\n",
        "\n",
        "Two types of resampling are:\n",
        "\n",
        "* **Upsampling**: Where you increase the frequency of the samples, such as from minutes to seconds.\n",
        "* **Downsampling**: Where you decrease the frequency of the samples, such as from days to months.\n",
        "\n",
        "There are perhaps two main reasons why you may be interested in resampling your time series data:\n",
        "\n",
        "* **Problem Framing**: Resampling may be required if your data is available at the same frequency that you want to make predictions.\n",
        "* **Feature Engineering**: Resampling can also be used to provide additional structure or insight into the learning problem for supervised learning models.\n",
        "Let’s make resampling more concrete by looking at a real dataset and some examples.\n",
        "\n",
        "We will use previous dataset \"Daily minimum temperatures in Melbourne, Australia, 1981-1990\"\n",
        "\n",
        "Imagine that we want average weekly temparature information. In this case we have to unsample the information from daily to weekly.\n",
        "\n",
        "We can use this function to transform our daily dataset into a weekly dataset by calling resampling and specifying the preferred frequency of calendar week frequency or \"W\"."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Time Series Frequencye for `.resample()` Periodicity**   \n",
        "\n",
        "**Most commonly used time series frequency are:**     \n",
        " - W - weekly frequency    \n",
        " - M - month end frequency    \n",
        " - SM - semi-month end frequency (15th and end of month)    \n",
        " - Q - quarter end frequency    \n",
        "\n",
        "**The full list of Pandas `DateTime` frequency codes that can be used as `.resample()` rules**\n",
        "\n",
        " - B - business day frequency    \n",
        " - C - custom business day frequency    \n",
        " - D - calendar day frequency    \n",
        " - W - weekly frequency    \n",
        " - M - month end frequency    \n",
        " - SM - semi-month end frequency (15th and end of month)    \n",
        " - BM - business month end frequency    \n",
        " - CBM - custom business month end frequency    \n",
        " - MS - month start frequency   \n",
        " - SMS - semi-month start frequency (1st and 15th)    \n",
        " - BMS - business month start frequency    \n",
        " - CBMS - custom business month start frequency    \n",
        " - Q - quarter end frequency    \n",
        " - BQ - business quarter end frequency    \n",
        " - QS - quarter start frequency    \n",
        " - BQS - business quarter start frequency    \n",
        " - A, Y - year end frequency    \n",
        " - BA, BY - business year end frequency    \n",
        " - AS, YS - year start frequency    \n",
        " - BAS, BYS - business year start frequency    \n",
        " - BH - business hour frequency    \n",
        " - H - hourly frequency    \n",
        " - T, min - minutely frequency    \n",
        " - S - secondly frequency    \n",
        " - L, ms - milliseconds    \n",
        " - U, us - microseconds    \n",
        " - N - nanoseconds    \n"
      ],
      "metadata": {
        "id": "JWOFxRzRSu3S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY6IWErfwhLL"
      },
      "source": [
        "melbourne_temp.resample('W').mean().head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCKzJQDtxN64"
      },
      "source": [
        "Check yourself that in the \"temp\" is realy average temperature for respective week.\n",
        "\n",
        "Instead of creating new rows between existing observations, the [resample()](https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html) function in pandas will group all observations by the new frequency.\n",
        "\n",
        "This operation is called *downsampling*.\n",
        "\n",
        "We can downsample the data using the alias \"A\" for year-end frequency and this time use `min` to calculate the miminum (or `max` for maximum, everything you need) temperature of each year."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hePbipJxrgO"
      },
      "source": [
        "melbourne_temp.resample('A').min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbz3Pv31xuAk"
      },
      "source": [
        "Resampling is also a fast way to smooth in some essence the time series. For instance, the time series of monthly averages has much less peaks or outliers and allows tracking the periodicity.\n",
        "\n",
        "Much accurate way to smooth a time series is the cacluation of rolling average that is the average value of the current point and N previous points. It can be calcualted using [rolling](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html?highlight=rolling#pandas.DataFrame.rolling) pandas's method where we should define the window, i.e. amount of points for average calculation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8kylQKwEX6U"
      },
      "source": [
        "## Rolling Average (Moving Average, Running Average)\n",
        "\n",
        "(https://en.wikipedia.org/wiki/Moving_average)\n",
        "\n",
        "In statistics, a moving average (rolling average or running average) is a calculation to analyze data points by creating a series of averages of different subsets of the full data set. It is also called a moving mean (MM) or rolling mean and is a type of finite impulse response filter. Variations include: simple, cumulative, or weighted forms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxvTr9IuFLuT"
      },
      "source": [
        "Rolling Average is an example of a smoothing technique which is applied to time series to remove the fine-grained variation between time steps. (https://machinelearningmastery.com/moving-average-smoothing-for-time-series-forecasting-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xlXGwKjx7K_"
      },
      "source": [
        "# Draw initial time series and make it transparent\n",
        "ax = melbourne_temp.plot(alpha=0.25)\n",
        "# Draw montly average values\n",
        "melbourne_temp.resample('M').mean().plot(ax=ax)\n",
        "# Draw roling average that takes into account 25 points\n",
        "melbourne_temp.rolling(10).mean().plot(ax=ax)\n",
        "# Specify legend labels\n",
        "ax.legend([\"daily data\", \"montly average\", \"roling mean\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk-jGFP3x-5e"
      },
      "source": [
        "If you set the hourly frequency in the `resample()` function, then NaN values will be created, because there are no more tiny distribution of the temperature.\n",
        "\n",
        "This procedure is called *upsampling*. Before you run this procedure, think if we have the temperature values for every hour. \n",
        "\n",
        "What do you expect to see? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "829yq3lgyECI"
      },
      "source": [
        "upsampled = melbourne_temp.resample('H').mean()\n",
        "upsampled.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjkdxM5iyG_Q"
      },
      "source": [
        "But we can [interpolate](https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.interpolate.html) the missing values at this new frequency.\n",
        "\n",
        "The Series pandas's object provides the interpolate function to interpolate missing values. A good starting point is to use a `linear interpolation`. This draws a straight line between available data and fills in values at the chosen frequency from this line."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upsampled.head(30)"
      ],
      "metadata": {
        "id": "8OIED4nqUcmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmRlWf3QymHR"
      },
      "source": [
        "interpolated = upsampled.interpolate(method='linear')\n",
        "interpolated.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YVpiIhkQq1yE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kirCEWeKAJn5"
      },
      "source": [
        "## Another example of Time Series and Forecasting\n",
        "\n",
        "Based on the book Introduction to Time Series and Forecasting by Brockwell and Davis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erIybKUxARwr"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4yfnhrEAUf8"
      },
      "source": [
        "# This is just to select the style of the generated plots. Feel free to experiment\n",
        "# and select other styles that you may like better. Notice that Style sheets are \n",
        "# designed to be composed together. So you can have a style sheet that customizes \n",
        "# colors and a separate style sheet that alters element sizes for presentations. \n",
        "# print(plt.style.available)\n",
        "matplotlib.style.use(['seaborn-talk', 'seaborn-ticks', 'seaborn-whitegrid'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Qw0tnb1FtQ8K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFbwlzIxAWRM"
      },
      "source": [
        "### Australian red wine \"sales\", (thousands of litres) monthly, Jan 80 - Oct 91"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEFv_zcxAZzm"
      },
      "source": [
        "The file `AusWineSales.csv` contains the monthly sales of Australian red wines in for the period Jan-1980 to Oct-1991. Let us take a peak at the [data file](https://raw.githubusercontent.com/rajansharm/Time-Series-Analysis/master/AusWineSales.csv).\n",
        "\n",
        "Additional Time Series Analysis of the Australian Wines data set can be found [here](https://github.com/rajansharm/Time-Series-Analysis/blob/master/Rajan_TimeSeries.ipynb). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXmK9d5vApxE"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/rajansharm/Time-Series-Analysis/master/AusWineSales.csv -o AusWineSales.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxUM4KtgAyde"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/rajansharm/Time-Series-Analysis/master/AusWineSales.csv\")  # if you use this line, you do not \n",
        "                                                                                                               # need the above cell with !curl\n",
        "#df = pd.read_csv(\"AusWineSales.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xzqSP4WA2uv"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eswd5dLA5WD"
      },
      "source": [
        "Pandas is relatively smart and can infer the data type of a column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcp-47EtA6wQ"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe"
      ],
      "metadata": {
        "id": "mtVTYBv7Wq3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V444KQSJAJ7Z"
      },
      "source": [
        "In this case pandas figured out that Sales is a `number`, but not that Date is an `object`.\n",
        "\n",
        "We can now try to plot directly the contents of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXn1Rz2SBJBP"
      },
      "source": [
        "df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi4VhrH2BNhW"
      },
      "source": [
        "Why do we have a number on the x-axis?\n",
        "\n",
        "The plot would look better if we had the x-axis to be a date, instead of a number. For that, we use the corresponding Pandas functions to convert the columns into the appropriate formats. We also tell Pandas to convert the Date column into the key for each row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoxhrgqVBWw7"
      },
      "source": [
        "df[\"YearMonth\"] = pd.to_datetime(df[\"YearMonth\"])\n",
        "df.set_index(keys=\"YearMonth\", inplace=True)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)"
      ],
      "metadata": {
        "id": "0k_O9yEnXRgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot()"
      ],
      "metadata": {
        "id": "rjLIwDFhXjzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq-8bUWmCYPk"
      },
      "source": [
        "df_Red = df[[\"Red\"]]\n",
        "df_Sparkling = df[[\"Sparkling\"]]\n",
        "df_Sweetwhite = df[[\"Sweetwhite\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qFhzQJhDnH-"
      },
      "source": [
        "df_Red.plot(figsize=(15,7), grid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8kzLSS-DisW"
      },
      "source": [
        "df_Sparkling.plot(figsize=(15,7), grid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8ERGhOIDS7Q"
      },
      "source": [
        "df_Sweetwhite.plot(figsize=(15,7), grid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkX_PwZXDrFl"
      },
      "source": [
        "It appears from the graph that the sales have an upward trend and a seasonal pattern with a peak in July and a trough in January.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8GrqOmxDyZQ"
      },
      "source": [
        "#### Jumping Ahead: Lag plots, autocorrelation plots, and decompositions.\n",
        "\n",
        "Pandas provides two types of plots that can be used for the analysis of time series: the lag_plot and the autocorrelation_plot. We can also use the seasonal decomposition functionality of statsmodels to separate the time series into a trend, seasonal component, and residual noise. We will go quickly over these for now, mainly for demo purposes. Proper treatment of these topics require deeper analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omQSCoXxD3Zp"
      },
      "source": [
        "### Lag plot\n",
        "\n",
        "The lag plot shows the value of the series at time $t$ vs. its value at time $t+1$. If there is no dependency (i.e., the time series is noise) then the lag plot is a scatterplot without any sign of correlation. If we can see a pattern and a correlation, then the series exhibits autocorrelation. For example, below we can see that there is a rather strong correlation of the two variables, indicating that the sales in time $t+1$ is similar to the sales at time $t$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HhOODBqD-YE"
      },
      "source": [
        "from pandas.plotting import lag_plot\n",
        "lag_plot(df_Red[\"Red\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqaNdYpEJ6Q"
      },
      "source": [
        "### Autocorrelation Plot\n",
        "In a more general setting, we want to also see if the value of the series at time $t$ is predictive of the value at time $t+n$. Such dependency would indicate that there is autocorrelation in the series. The autocorrelation plot shows the correlation value for various values of $n$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RE6YFq0ENFH"
      },
      "source": [
        "from pandas.plotting import autocorrelation_plot\n",
        "\n",
        "autocorrelation_plot(df_Red[\"Red\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6Avvmwahqv1e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkT-1HQzES7G"
      },
      "source": [
        "### Trend/Seasonal Decomposition\n",
        "\n",
        "We will analyze red wines. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW36ozPvEVYj"
      },
      "source": [
        "\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# We decompose assumming a 12-month periodicity. \n",
        "# There is a weekly component as well, which we ignore.\n",
        "# We can also specify a multiplicative instead of an additive model\n",
        "# The additive model is Y[t] = T[t] + S[t] + e[t]\n",
        "# The multiplicative model is Y[t] = T[t] * S[t] * e[t]\n",
        "decomposition = seasonal_decompose(df_Red['Red'], model='multiplicative', freq=12)  \n",
        "fig = plt.figure()  \n",
        "fig = decomposition.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmwewbXXEd1T"
      },
      "source": [
        "### Accessing individual components of the decomposition\n",
        "Once we have the decomposed time series model, we can also access the different components.\n",
        "\n",
        "For example, we can get the trend of the time series, after removing the seasonality component:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTk04VO4Egwd"
      },
      "source": [
        "# The outcome is a pandas Series, which is effectively the same as a single column of dataframe\n",
        "decomposition.trend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "papebeQVEiwe"
      },
      "source": [
        "decomposition.trend.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "V53ocZUYqZPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summary and Additional References    \n",
        "\n",
        "\n",
        "See the article [ARIMA for Time Series with Python from MachineLearningMastery](https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/) on the development of analysis and use of the `ARIMA` model for the Melbourne temperature data set. \n",
        "\n",
        "\n",
        "*note: see the following CST3512 notebooks for additional time series material:*    \n",
        "\n",
        "* **[CST3512_TimeSeries_AirPassengers](https://colab.research.google.com/drive/1t2InZbknRMJBmXs0gq0NcEhIuCduD3tq?usp=sharing)**    \n",
        "\n",
        "* **[DataQuest Time Series Energy Tutorial](https://colab.research.google.com/drive/1TIVLt5XQWBpZGwonb3GTByHFo8LTcPL4?usp=sharing)**    \n",
        "\n",
        "\n",
        "As mentioned at the start of this notebook, here is information on a few time series examples in the real world:\n",
        "\n",
        "* [Central England Temperatures 1659-2016](http://clivebest.com/blog/?p=7603)\n",
        "* [U.S. Real GDP Per Capita (1900 – 2017): Current Economy vs Historical Trend Line](https://bfi.uchicago.edu/insight/chart/u-s-real-gdp-per-capita-1900-2017-current-economy-vs-historical-trendline/)\n",
        "* [New York City's overall water consumption](https://www.reddit.com/r/dataisbeautiful/comments/9tzmkp/oc_surprisingly_new_york_citys_overall_water/)\n",
        "\n"
      ],
      "metadata": {
        "id": "FuotMSKxqaEh"
      }
    }
  ]
}