{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNGrpoCNofaNQKnxQ/fLsx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorPatrickSlatraigh/CST3512/blob/main/CST3512_Class19_TimeSeries_AirPassengers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CST3512 Class 19    \n",
        "**Time Series Analysis**    \n",
        "**Airline Passenger Data**    \n",
        "    \n",
        "*reference: [NIST Engineering Statistics Handbook 6.4.4.2](https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc442.htm)*\n",
        "    \n",
        "*Examples in this notebook are from a [blog entry, Medium article](https://medium.com/@stallonejacob/time-series-forecast-a-basic-introduction-using-python-414fcb963000), and [GitHub repos](https://github.com/jacobstallone/Time_Series_ARIMA--Blog-and-code-) entitled 'Time Series ARIMA' by Jacob Stallone, on November 9, 2019.*     \n",
        "\n",
        "Data is courtesy of [Jacob Stallone's copy](https://github.com/jacobstallone/Time_Series_ARIMA--Blog-and-code-/blob/master/AirPassengers.csv) of an [original Kaggle source](https://www.kaggle.com/datasets/chirag19/air-passengers).    \n",
        "\n",
        "\n",
        "<center><i>This notebook is available at https://bit.ly/cst3512cl19</i></center>    \n",
        "    \n",
        "\n",
        "versions: Spring 2021 by Professor Elena Filatova; Nov-2021 by Professor Patrick; updated: Mar-2023.     \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "JVtACvBn4B0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vjrvvKdN53Jt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time Series Forecast : A basic introduction using Python**    \n",
        "\n",
        "\n",
        "\n",
        "Time series data is an important source for information and strategy used in various businesses. From a conventional finance industry to education industry, they play a major role in understanding a lot of details on specific factors with respect to time. I recently learnt the importance of Time series data in the telecommunication industry and wanted to brush up on my time series analysis and forecasting information. \n",
        "\n",
        "\n",
        "This notebook works through a simple example using Python.    \n",
        "\n",
        "\n",
        "Time series forecasting is basically the machine learning modeling for Time Series data (years, days, hour, etc.) for predicting future values using Time Series modeling. This approach helps if your data in serially correlated.  \n",
        "\n"
      ],
      "metadata": {
        "id": "jb8p8XG7VGGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lkQg9-tUgas6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekPp6hqzGbYz"
      },
      "source": [
        "##Housekeeping: Import Modules, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ekSIStSKGbY0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np    \n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 15, 6\n",
        "\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIYbRGl8GbY1"
      },
      "source": [
        "https://matplotlib.org/users/customizing.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVPFx4wGGbY2"
      },
      "source": [
        "The dataset is from kaggle , Let's explore it using a copy that Jacob Stallone posts on his GitHub.   Pull that file into the current working directory with `!curl` as follows.    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://raw.githubusercontent.com/jacobstallone/Time_Series_ARIMA--Blog-and-code-/master/AirPassengers.csv\"  -o AirPassengers.csv"
      ],
      "metadata": {
        "id": "Co7ZqmCyGg2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Read the dataset into a Pandas dataframe called `data`."
      ],
      "metadata": {
        "id": "j8P_QZvyJSn8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jGRVLuaGbY2"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('AirPassengers.csv')\n",
        "print(data.head())\n",
        "print('\\n Data Types:')\n",
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "B5XBCUD7gZFK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98D7PcAgGbY4"
      },
      "source": [
        "##Dataset Description "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuJdkDRNGbY4"
      },
      "source": [
        "The data contains a particular month and number of passengers travelling in that month. The data type here is object (month).     \n",
        "\n",
        "Convert it into a Time series object and use the Month column as the index.    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBEx8ZHNGbY5"
      },
      "source": [
        "\n",
        "\n",
        "Timestamps are useful objects for comparisons.     \n",
        "\n",
        "Create a timestamp object with the `pd.to_datetime()` function and a string specifying the date. These timestamps are useful for logical filtering with dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsURr0wPGbY6"
      },
      "outputs": [],
      "source": [
        "# from datetime import datetime\n",
        "\n",
        "con=data['Month']\n",
        "data['Month']=pd.to_datetime(data['Month'])\n",
        "data.set_index('Month', inplace=True)\n",
        "#check datatype of index\n",
        "data.index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "id": "TbO4FSCxIdBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(5)"
      ],
      "metadata": {
        "id": "lGmGlyKZIir9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data type is `datetime64[ns]`. For this notebook example it is read into a series rather than a dataframe but the approach works regardless of whether the data is in a series or a dataframe.   "
      ],
      "metadata": {
        "id": "Sl7iOZD9WGrI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9v6yzqbGbY7"
      },
      "outputs": [],
      "source": [
        "#convert to time series:\n",
        "ts = data['#Passengers']\n",
        "ts.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZNGnRzWGbY7"
      },
      "source": [
        "###Explore properties of the date-time based index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6V6UDGeGbY8"
      },
      "outputs": [],
      "source": [
        "#1. Specify the index as a string constant:\n",
        "ts['1949-01-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVM6LaMRGbY8"
      },
      "outputs": [],
      "source": [
        "#2. Import the datetime library and use 'datetime' function:\n",
        "from datetime import datetime\n",
        "ts[datetime(1949,1,1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsjlSw3HGbY8"
      },
      "outputs": [],
      "source": [
        "#1. Specify the entire range:\n",
        "ts['1949-01-01':'1949-05-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-YA4pZPGbY9"
      },
      "outputs": [],
      "source": [
        "#2. Use ':' if one of the indices is at an end\n",
        "ts[:'1949-05-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu4acX5UGbY9"
      },
      "outputs": [],
      "source": [
        "#All rows of 1962:\n",
        "ts['1949']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "84-XPu1BgW3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Stationarity**    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y9GtC4GuMNe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stationarity** testing is a crucial concept in time-series analysis that helps us determine whether a `time-series` data set exhibits consistent patterns over time. `Time-series` data is simply a sequence of data points collected or recorded at regular intervals, such as daily stock prices or monthly sales figures. In data science, understanding the properties of `time-series` data is vital because it impacts the quality and accuracy of our predictions and analyses.    "
      ],
      "metadata": {
        "id": "Mjx-Jyl1MWOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Characteristics of **Stationarity**    "
      ],
      "metadata": {
        "id": "F_lXufgFMkSW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcy9BeskGbY-"
      },
      "source": [
        "\n",
        "**Stationarity** is a very important concept in Time Series Analysis. In order to apply a time series model, it is important for the Time series to be stationary; in other words all its statistical properties (mean,variance) remain constant over time. This is done basically because if you take a certain behavior over time, it is important that this behavior is same in the future in order for us to forecast the series.     \n",
        "\n",
        "There are a lot of statistical theories to explore stationary series than non-stationary series.  In practice we can assume the series to be stationary if it has constant statistical properties over time and these properties can be:\n",
        "* constant **mean**\n",
        "* constant **variance**\n",
        "* an **auto-co-variance** that does not depend on time       \n",
        "    \n",
        "A `time-series` data set is considered stationary if its statistical properties, such as:\n",
        "*  `mean` (average)    \n",
        "*  `variance` (spread)    \n",
        "*  `autocorrelation` (relationship between data points at different time lags)    \n",
        ", remain constant over time. In simple terms, this means that the overall pattern of the data does not change as time progresses. Stationary `time-series` data is desirable because it simplifies modeling and forecasting, allowing us to make more accurate predictions.    \n",
        "\n",
        "The characteristics of **Stationarity** can be easily tested using statistical techniques in Python.    \n",
        "    \n",
        "An excellent way to understand you stationarity in a `Time Series` is by visually inspecting the plot.    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Some additional housekeeping to import plot converters*    "
      ],
      "metadata": {
        "id": "IFyOoA0EKHm9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQweF5_JGbY-"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbFa3wffGbY-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ts)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNOiQYUHGbY_"
      },
      "source": [
        "It’s clear from the plot that there is an overall increase in the trend and with some seasonality in it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Rqv9t14WgU1M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHdPb116GbY_"
      },
      "source": [
        "###Stationarity Testing "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stationarity testing involves performing statistical tests on the `time-series` data to check for the presence or absence of stationarity. Some of the popular tests include:\n",
        "* **<font color=blue>[Augmented Dickey-Fuller](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test)</font>** (ADF) test    \n",
        "* **[Kwiatkowski-Phillips-Schmidt-Shin](https://en.wikipedia.org/wiki/KPSS_test)** (KPSS) test    \n",
        "* **[Phillips-Perron](https://en.wikipedia.org/wiki/Phillips%E2%80%93Perron_test)** (PP) test    \n",
        "    \n",
        "These tests compare specific properties of the data against a null hypothesis, which is a statement that assumes no stationarity. If the test results suggest that we can reject the null hypothesis, it means that the data is likely to be stationary.    \n"
      ],
      "metadata": {
        "id": "PajtXd_BNdC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In the [blog entry, Medium article](https://medium.com/@stallonejacob/time-series-forecast-a-basic-introduction-using-python-414fcb963000) '**Time Series ARIMA**', Jacob Stallone has provided a function for testing **stationarity** which will be used often in this Time Series notebook. Some of the concepts utilized by Stallone include:    \n",
        "\n",
        "* **Plotting Rolling Statistics** - The function will plot the moving mean or moving Standard Deviation. This is still a visual method.     \n",
        "\n",
        "    *NOTE: moving mean and moving standard deviation — At any instant ‘t’, we take the mean/std of the last year which in this case is 12 months.*\n",
        "\n",
        "* **<font color=blue>Dickey-Fuller Test</font>** - This is one of the statistical tests for checking stationarity. First we consider the null hypothesis: the time series is non- stationary. The result from the rest will contain the test statistic and critical value for different confidence levels. The idea is to have Test statistics less than critical value, in this case we can reject the null hypothesis and say that this Time series is indeed stationary.    \n",
        "\n",
        "    *More details for <b><font color=blue>Dickey-Fuller Test</font></b>.*\n",
        "\n",
        "    Function details:\n",
        "\n",
        "  * **mean**    \n",
        "  * **Standard Deviation** (instead of variance)    \n",
        "  * **Plot Original Series**     \n",
        "  * **Plot Mean**     \n",
        "  * **Plot std**    \n",
        "  * **Plot Dickey-Fuller Test**    \n"
      ],
      "metadata": {
        "id": "aJtwWBZEX_xu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####<u>`.test_stationarity()`</u>     \n",
        "    \n",
        "A function to analyze a `time series` and test **stationarity**"
      ],
      "metadata": {
        "id": "wr__itIqKY-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Additional housekeeping to import `adfuller` from `statsmodels` to test stationarity*"
      ],
      "metadata": {
        "id": "k6Bt9z7cKgop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller"
      ],
      "metadata": {
        "id": "O9qqK3eJKbdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Based on the deprecation warning in the execution of the last snippet, the following import or some derivative thereof may warrant exection.*"
      ],
      "metadata": {
        "id": "ve7HGfYOLMra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# No need to run this import if no deprecation warning on last snippet\n",
        "import pandas.util.testing as tm"
      ],
      "metadata": {
        "id": "-XfC3hhALF1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function `test_stationarity()` to perform various tests of stationarity as described above:    \n",
        "\n",
        "* **mean**    \n",
        "* **Standard Deviation** (instead of variance)    \n",
        "* **Plot Original Series**     \n",
        "* **Plot Mean**     \n",
        "* **Plot std**    \n",
        "* **Plot Dickey-Fuller Test**    \n"
      ],
      "metadata": {
        "id": "raVTAp_3Kr8h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QU-nClzMGbY_"
      },
      "outputs": [],
      "source": [
        "def test_stationarity(timeseries):\n",
        "    \n",
        "    #Determing rolling statistics\n",
        "    rolmean = pd.Series(timeseries).rolling(window=12).mean()\n",
        "    rolstd = pd.Series(timeseries).rolling(window=12).std()\n",
        "\n",
        "    #Plot rolling statistics:\n",
        "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
        "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
        "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('Rolling Mean & Standard Deviation')\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    #Perform Dickey-Fuller test:\n",
        "    print('Results of Dickey-Fuller Test:')\n",
        "    dftest = adfuller(timeseries, autolag='AIC')\n",
        "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "        dfoutput['Critical Value (%s)'%key] = value\n",
        "    print(dfoutput)    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the tests of stationarity for the time series `ts` by parsing the time series data into the new `test_stationarity()` function.\n"
      ],
      "metadata": {
        "id": "tbs2_TapK3Be"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNfJHJWTGbZA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "test_stationarity(ts)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This series is not **stationary** because:    \n",
        "\n",
        "* **mean** is increasing even though the **std** is small.\n",
        "* **Test Stat** is > critical value.\n",
        "\n",
        "\n",
        "*Note: the signed values are compared and the absolute values.*    \n",
        "\n"
      ],
      "metadata": {
        "id": "j-iW_dfiYzp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`.test_adf()`      "
      ],
      "metadata": {
        "id": "vRFJ7dArKqOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to invoke the <font color=blue><b>**Augmented Dickie Fuller (ADF) Test**</font> analysis of a series and test of **stationarity**    "
      ],
      "metadata": {
        "id": "246ypOFWKyUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adf_test(arg_series):\n",
        "    result = adfuller(arg_series)\n",
        "    print('ADF Statistic:', result[0])\n",
        "    print('p-value:', result[1])\n",
        "    print('Critical Values:')\n",
        "    for key, value in result[4].items():\n",
        "        print('\\t%s: %.3f' % (key, value))\n",
        "    if result[0] < result[4]['5%']:\n",
        "        print('\\nThe time series is stationary.')\n",
        "        return(True)\n",
        "    else:\n",
        "        print('\\nThe time series is non-stationary.')\n",
        "        return(None)"
      ],
      "metadata": {
        "id": "GE224II5Kxqa"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf_test(ts)"
      ],
      "metadata": {
        "id": "Uvtv7CFPLT49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stationarity testing** is an essential step in `time-series` analysis that helps us determine if the data exhibits consistent patterns over time. By ensuring stationarity, we can build more accurate and reliable models for prediction and analysis. As data science students, understanding the concept of stationarity and its importance will help you better approach `time-series` data in your projects and research.    \n"
      ],
      "metadata": {
        "id": "rF50wLOgO1si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ElM278KegStP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bmAuOwDGbZA"
      },
      "source": [
        "###Transformation Techniques for Times Series Stationarity    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we continue, let's read a copy of the data into a new `data` Dataframe."
      ],
      "metadata": {
        "id": "is6jcXG8Nk7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv', \n",
        "                   header=0, index_col=0, parse_dates=True).squeeze(\"columns\")"
      ],
      "metadata": {
        "id": "ew05gCP1NtaR"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In many cases, `time-series` data may not be stationary, but it can be transformed to achieve stationarity. This can be often be done through one or more of the following processes:    \n",
        "\n",
        "1. **differencing**, where we create a new `time series` by computing the differences between consecutive data points.    \n",
        "\n",
        "2. **log or square-root stabilization**, where we create a new `time series` by taking the logarithm or square root of the series to stabilize non-constant variance.         \n",
        "    \n",
        "3. **trend residuals**, where we create a new `time series` by computing the residuals from some trend pattern.    \n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "yCMlxfnOOGgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1. <u>Differencing to Achieve Stationarity</u>     \n",
        "    "
      ],
      "metadata": {
        "id": "yXhNnIjxRkU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Differencing** can be applied multiple times if necessary, until the resulting `time series` becomes stationary. After analyzing and modeling the stationary data, we can then reverse the transformation to obtain predictions in the original scale.    \n",
        "    \n",
        "To **difference** the data we subject the prior observation from each observation and work with a series of those **differences**. That is, given the series `Zt`, we create the new series:\n",
        "```    \n",
        "Y[i] =Z[i] − Z[i−1]    \n",
        "```    \n",
        "\n",
        "The differenced data will contain one less point than the original data.     \n",
        "Although you can difference the data more than once, one difference is usually sufficient.    "
      ],
      "metadata": {
        "id": "08HfuxQhRpqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1.a Example: <u>Differencing to Achieve Stationarity with AirPassengers Dataset</u>    \n"
      ],
      "metadata": {
        "id": "ecOE2TN3a5Nx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following example attempts to use **differencing** to achieve **stationarity** with the AirPassengers dataset from the `statsmodels` library         \n",
        "    \n",
        "The script loads the AirPassengers dataset, plots the original `time series`, performs first-order differencing to achieve stationarity, plots the differenced `time series`, and performs the **<font color=blue>Augmented Dickey-Fuller</font> (ADF) test to check for stationarity. The ADF test results are printed to the console, along with a message indicating whether the `time series` is **stationary** or **non-stationary**."
      ],
      "metadata": {
        "id": "vDNFBRJDgrfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the original time series\n",
        "plt.plot(data)\n",
        "plt.title('AirPassengers Time Series')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.show()\n",
        "\n",
        "# perform first-order differencing\n",
        "diff = data.diff().dropna()\n",
        "\n",
        "# plot the differenced time series\n",
        "plt.plot(diff)\n",
        "plt.title('Differenced AirPassengers Time Series')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.show()\n",
        "\n",
        "# perform ADF test to check for stationarity\n",
        "adf_test(diff)"
      ],
      "metadata": {
        "id": "FXY3R-aJbBWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, simple **differencing** alone does not achieve **stationarity** in the case of the AirPassengers dataset.    "
      ],
      "metadata": {
        "id": "Jp8KHzrJdSif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. <u>Log or Square Root Stabilization</u>    \n",
        "    \n",
        "Log or square root stabilization can be used to transform non-stationary data into stationary data.      \n",
        "* **Logarithmic transformation**: stabilizes variance.  A new `time series` is derived as the `log` of the original series.       \n",
        "* **Square Root transformation** reduces the effect of extreme values.  A new `time series` is derived as the `square root` of the original series.     \n",
        "    \n",
        "These transformations can help in achieving stationarity and make the time series suitable for statistical analysis."
      ],
      "metadata": {
        "id": "oUFoFW56VoNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2.a Example: <u>Logarithmic Transformation to Achieve Stationarity with AirPassengers Dataset</u>     "
      ],
      "metadata": {
        "id": "qshwkADlkG-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following example demonstrates the use of **logarithmic transformation** to attempt to achieve **stationarity** in `time series` data using the AirPassengers dataset available in the `statsmodels` library.    \n",
        "    \n",
        "The script loads the AirPassengers dataset, applies **logarithmic transformation** to the `time series`, plots the logarithmically transformed time series, and performs the **<font color=blue>Augmented Dickey-Fuller</font>** (ADF) test to check for stationarity. The ADF test results are printed to the console, along with a message indicating whether the `time series` is **stationary** or **non-stationary**."
      ],
      "metadata": {
        "id": "xKXCO-eSkpAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply logarithmic transformation to the time series\n",
        "log_data = np.log(data)\n",
        "\n",
        "# plot the logarithmically transformed time series\n",
        "plt.plot(log_data)\n",
        "plt.title('Logarithmically Transformed AirPassengers Time Series')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Log(Number of Passengers)')\n",
        "plt.show()\n",
        "\n",
        "# perform ADF test to check for stationarity\n",
        "adf_test(log_data)"
      ],
      "metadata": {
        "id": "YCXIJfpdkkSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, simple **logarithmic transformation** alone does not achieve **stationarity** in the case of the AirPassengers dataset.    "
      ],
      "metadata": {
        "id": "WQlfqTXxlduY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2.b Example: <u>Square Root Transformation to Achieve Stationarity with AirPassengers Dataset</u>     "
      ],
      "metadata": {
        "id": "lDpmgmNXmffK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following example attempts to demonstrate the use of **square root transformation** to achieve **stationarity** in `time series` data using the AirPassengers dataset available in `statsmodels` library.    \n",
        "    \n",
        "The script loads the AirPassengers dataset, applies **square root transformation** to the `time series`, plots the square root transformed `time series`, and performs the **<font color=blue>Augmented Dickey-Fuller</font>** (ADF) test to check for stationarity. The ADF test results are printed to the console, along with a message indicating whether the time series is **stationary** or **non-stationary**."
      ],
      "metadata": {
        "id": "4HptqfYOnULJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply square root transformation to the time series\n",
        "sqrt_data = np.sqrt(data)\n",
        "\n",
        "# plot the square root transformed time series\n",
        "plt.plot(sqrt_data)\n",
        "plt.title('Square Root Transformed AirPassengers Time Series')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Square Root of Number of Passengers')\n",
        "plt.show()\n",
        "\n",
        "# perform ADF test to check for stationarity\n",
        "adf_test(sqrt_data)"
      ],
      "metadata": {
        "id": "QmlHxFhCnwLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, simple **logarithmic transformation** alone does not achieve **stationarity** in the case of the AirPassengers dataset.    "
      ],
      "metadata": {
        "id": "ZJaOh8dCnwhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YZ-Y8_PFRf49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. <u>Trend Residuals to Achieve Stationarity</u>    \n",
        "\n",
        "Trend residuals can be used to achieve **stationarity** in `time-series` data by removing the underlying trends in the data. This is accomplished by fitting a trend line or curve to the original data and then subtracting the fitted values from the actual data points, resulting in a new time series of residuals. The residual `time series`, which represents the fluctuations around the trend, is often more stationary, making it suitable for further analysis and modeling."
      ],
      "metadata": {
        "id": "3BiWKcgAU47Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3.a1 Example: <u>Trend Residuals to Achieve Stationarity with AirPassengers Dataset</u>        \n"
      ],
      "metadata": {
        "id": "8v4M-7ytd803"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following example attempts to demonstrate the use of **trend residuals** to achieve **stationarity** in `time series` data using the AirPassengers dataset available in the `statsmodels` library.   \n",
        "\n",
        "The script loads the AirPassengers dataset, decomposes the `time series` into `trend`, `seasonal`, and `residual` components, extracts the residual component, plots the residual time series, and performs the <font color=blue>**Augmented Dickey-Fuller**</font> (ADF) test to check for **stationarity**. The ADF test results are printed to the console, along with a message indicating whether the `time series` is **stationary** or **non-stationary**. \n"
      ],
      "metadata": {
        "id": "-5Fs9PW3fM1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decompose the time series into trend, seasonal, and residual components\n",
        "decomposition = seasonal_decompose(data, model='multiplicative')\n",
        "\n",
        "# extract the residual component\n",
        "residual = decomposition.resid.dropna()\n",
        "\n",
        "# plot the residual component\n",
        "plt.plot(residual)\n",
        "plt.title('AirPassengers Residual Time Series')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.show()\n",
        "\n",
        "# perform ADF test to check for stationarity\n",
        "adf_test(residual)"
      ],
      "metadata": {
        "id": "hcAnhtXlfIYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see from the example above, **trend residuals** appear to achieve **stationarity** in the case of the AirPassengers dataset, **BUT** bear in mind that the residuals series is after both `trend` and `seasonality` are factored in.    "
      ],
      "metadata": {
        "id": "F-Vb7kOShiu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3.a2 Example: <u>Trend Residuals to Achieve Stationarity with AirPassengers Dataset</u>    \n",
        "**'numpy' for Only Linear Trend**    \n"
      ],
      "metadata": {
        "id": "aSnL_0Y34dCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, the `numpy.polyfit()` method can be used to determine a linear **trend** in a dataset without incorporating any **seasonality** decomposition.\n",
        "\n",
        "`numpy.polyfit(x, y, deg)` returns the coefficients of a polynomial of degree `deg` that best fits the data in `y` given the corresponding values in `x`. By setting `deg=1`, the method fits a straight line to the data, which represents a **linear trend**.\n",
        "\n",
        "Here is an example:"
      ],
      "metadata": {
        "id": "N7cwefIr4nAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the values from the dataset\n",
        "y = data.values\n",
        "x = np.arange(len(y))\n",
        "\n",
        "# fit a straight line to the data\n",
        "coefficients = np.polyfit(x, y, deg=1)\n",
        "trend = np.polyval(coefficients, x)\n",
        "\n",
        "# plot the original time series and the linear trend\n",
        "plt.plot(y)\n",
        "plt.plot(trend)\n",
        "plt.title('AirPassengers Time Series with Linear Trend')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.legend(['Original', 'Trend'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "roeHm-cm488I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate the residual from the **trend** using `numpy.polyfit()` and test the resulting series for **stationarity** using the AirPassengers dataset"
      ],
      "metadata": {
        "id": "HdlaUcmk49ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the values from the dataset\n",
        "y = data.values\n",
        "x = np.arange(len(y))\n",
        "\n",
        "# fit a straight line to the data\n",
        "coefficients = np.polyfit(x, y, deg=1)\n",
        "trend = np.polyval(coefficients, x)\n",
        "\n",
        "# compute the residual from the trend\n",
        "residual = y - trend\n",
        "\n",
        "# plot the original time series, trend, and residual\n",
        "plt.plot(y)\n",
        "plt.plot(trend)\n",
        "plt.plot(residual)\n",
        "plt.title('AirPassengers Time Series with Trend and Residual')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.legend(['Original', 'Trend', 'Residual'])\n",
        "plt.show()\n",
        "\n",
        "# perform ADF test to check for stationarity\n",
        "adf_test(residual)"
      ],
      "metadata": {
        "id": "0uAcs6xJ5uNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subtracting the observed values from the linear **trend** values provided by `numpy.polyval()`, it is clear that using only **trend residuals** does not provide a **stationary** series.    \n",
        "\n",
        "We will need to use more than one technique to transform the AirPassengers Dataset and achieve **stationarity**."
      ],
      "metadata": {
        "id": "lbWdTzPF5uhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nE-cUuo-rD0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Transforming the AirPassengers `Time Series` for Stationarity   \n",
        "    \n",
        "    \n",
        "There are two major factors that make our AirPassengers `time series` non-stationary.  They are:    \n",
        "* <u>Trend</u>: non-constant **mean**    \n",
        "* <u>Seasonality</u>: **variation pattern** at certain periods or time-frames.  We did not explore **seasonality** spceifically in the transformation techniques discussed above, though we did mention that our **trend residuals** examples utlized a model that incorporated **seasonality**.        \n",
        "    \n",
        "Our approach will be tomodel the **trend** and **seasonality** in the AirPassenger `time series`, so we can remove both and make the series **stationary**. Then we can go ahead and apply statistical forecasting to the **stationary** series. Finally, we will want to convert the forecasted values into the original context by applying the **trend** and **seasonality** constraints back to forecasted values so that they can be used in the original context.\n",
        "\n",
        "In summary, the approach is:\n",
        "\n",
        "1. Understand and model the **trend**\n",
        "2. Remove the **trend**    \n",
        "3. Understand and model the **seasonality**\n",
        "4. Remove the **seasonality**    \n",
        "5. Understand and model the underlying result\n",
        "6. Build a model which constucts predictions by - \n",
        "    * Using the #5 model    \n",
        "    * Layering in **seasonality** to enrich #5 model results\n",
        "    * Layering in **trend model** to enrich those results\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lF3AsS_jZ_Iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![CST3512_TimeSeries_TrendSeasonal.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "YKI4TC3J9ZgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let’s start by working on the **trend** piece.    "
      ],
      "metadata": {
        "id": "fZj_59cPrAsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Bo9GODBUgLL7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5wWqiQuGbZA"
      },
      "source": [
        "####1. **Trend Analysis**    \n",
        "\n",
        "The first step is to reduce the trend using some transformation, as we can see here that there is a strong positive trend. These transformation can be `log`, `sq-rt`, `cube root`, etc . Basically it penalizes larger values more than the smaller values. In this case we will use the logarithmic transformation.    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying a `log()` function to dampen large values.    "
      ],
      "metadata": {
        "id": "Yx49yqhTLsYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGFrzBKwGbZB"
      },
      "outputs": [],
      "source": [
        "ts_log = np.log(ts)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ts_log)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is some noise in realizing the forward trend here. There are some methods to model these trends and then remove them from the series. Some of the common ones are:    \n",
        "    \n",
        "a. **Smoothing** - using rolling/moving average    \n",
        "b. **Aggression** - by taking the mean for a certain time period (year/month)    \n",
        "    \n",
        "    \n",
        "The example which follows in this notebook uses **Smoothing**.     \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s84iOuT2auoC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_sem-cRGbZB"
      },
      "source": [
        "#####Smoothing the Series    \n",
        "\n",
        "\n",
        "In **smoothing** we usually take the past few periods or instances (rolling estimates).  Two methods of smoothing are considered in this notebook:    \n",
        "-   **Moving Average**    \n",
        "-   **Exponentially Weighted Moving Average (EWM)**.    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######**<u>Moving Average</u>**     \n",
        "\n",
        "First take n consecutive values (depending on the frequency if it is 1 year of monthly data, then take 12 values) and sum the values for that range of period then divide by the number of periods in the range. Pandas has a function for rolling estimates.    \n"
      ],
      "metadata": {
        "id": "CCE7xXPVE8AF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdPiErkqGbZB"
      },
      "source": [
        "#####Applying a Moving Average    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deriving a 12-month moving average of the data.     \n",
        "\n",
        "*note that any moving average of `n` periods will result in the creation of `null` values for the first `n-1` periods.*    \n"
      ],
      "metadata": {
        "id": "7rYZ8OdJMOIF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed6ZT2PnGbZC"
      },
      "outputs": [],
      "source": [
        "moving_avg = pd.Series(ts_log).rolling(12).mean()\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ts_log)\n",
        "plt.plot(moving_avg, color='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now subtract the rolling mean from the original series to calculate the period change in the moving average.    "
      ],
      "metadata": {
        "id": "uxhCLMVQMohm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2dvMBllOGbZC"
      },
      "outputs": [],
      "source": [
        "ts_log_moving_avg_diff = ts_log - moving_avg\n",
        "ts_log_moving_avg_diff.head(13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop the `null` or `NaN` values which resulted from calculating `n` number of periods in the moving average.    \n"
      ],
      "metadata": {
        "id": "w_aBe9GzMwog"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dgHyykDjGbZC"
      },
      "outputs": [],
      "source": [
        "ts_log_moving_avg_diff.dropna(inplace=True)\n",
        "ts_log_moving_avg_diff.head()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason there are null values is because we take the average of first 12 so 11 values are null. We can also see that in the visual representation. Thus it is dropped for further analysis. Now let’s parse it to the function to check for stationarity.    \n",
        "\n",
        "\n",
        "Invoke the `test_stationarity()` function defined earlier, using the newly calculated differences in the moving average of log function (`ts_log_moving_avg_diff`)    \n"
      ],
      "metadata": {
        "id": "_boDtmrJM-C6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2nHWDJEGbZC"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "test_stationarity(ts_log_moving_avg_diff)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice two things:    \n",
        "* The rolling values are varying slightly but there is no specific trend.\n",
        "* The test statistics is smaller than the 5 % critical values.     \n",
        "\n",
        "\n",
        "That tells us that we are 95% confident that this series is stationary.    \n",
        "\n",
        "\n",
        "In this example we can easily take a time period (12 months for a year), but there are situations where the time period range is more complex like stock price etc. So we use the exponentially weighted moving average (there are other weighted moving averages but for starters, lets use this). The previous values are assigned with a decay factor. Pandas again comes to the rescue with some awesome functions for it, like:"
      ],
      "metadata": {
        "id": "gEvjHOsXeiOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the  `.adf_test()` function we relied upon earlier to test for **stationarity**.     "
      ],
      "metadata": {
        "id": "9P66w0HMHmSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform ADF test to check for stationarity\n",
        "adf_test(ts_log_moving_avg_diff)"
      ],
      "metadata": {
        "id": "Fi8tct-xHcIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the exponentially-weighted moving average using the `ewm()` method."
      ],
      "metadata": {
        "id": "fbduCJK3NZVR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Boo5qwyYGbZD"
      },
      "source": [
        "###### <u>**Exponentially weighted moving average**</u>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrBW8DrsGbZD"
      },
      "outputs": [],
      "source": [
        "expwighted_avg = ts_log.ewm(halflife=12).mean()\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ts_log)\n",
        "plt.plot(expwighted_avg,color='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameter (halflife) is assumed to be 12, but that really depends on the characteristics of the data in the domain. Let’s check stationarity now."
      ],
      "metadata": {
        "id": "4ZhdMpgTexR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the difference in the exponentially-weighted moving average from the log of the time series (`ts_log_ewma_diff`) and testing for stationarity."
      ],
      "metadata": {
        "id": "yI0G2ILUNvh9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WunFxlHaGbZD"
      },
      "outputs": [],
      "source": [
        "ts_log_ewma_diff = ts_log - expwighted_avg\n",
        "plt.figure(figsize=(20,10))\n",
        "test_stationarity(ts_log_ewma_diff)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is stationary because:    \n",
        "\n",
        "* Rolling values have less variations in **mean** and **standard deviation** in magnitude.    \n",
        "* the **Test Statistic** is smaller than 1% of the critical value. So we can say we are almost 99% confident that this is stationary.    \n",
        "\n"
      ],
      "metadata": {
        "id": "RfQZRgU1f5xa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the  `.adf_test()` function we relied upon earlier to test for **stationarity**.     "
      ],
      "metadata": {
        "id": "8gQY0SXMIBHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform ADF test to check for stationarity\n",
        "adf_test(ts_log_ewma_diff)"
      ],
      "metadata": {
        "id": "ay9pSvy2IBHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "It5nL5UFgFrP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8gAJE0CGbZD"
      },
      "source": [
        "####3. **Analyzing and Treating Seasonality**      \n",
        "\n",
        "**(Along with the Trend)**     \n",
        "\n",
        "\n",
        "Previously we saw just trend part of the time series, now we will see both trend and seasonality. Most Time series have trends along with seasonality. There are two common methods to remove trend and seasonality, they are:    \n",
        "* **Differencing** - by taking difference using time lag    \n",
        "* **Decomposition** -  model both trend and seasonality, then remove them\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####<u>**Differencing**</u>        \n",
        "     \n",
        "First take the difference of the value at a particular time with that of the previous time.      \n",
        "     "
      ],
      "metadata": {
        "id": "IBAB7l53FdHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating a difference based on a shift in period. "
      ],
      "metadata": {
        "id": "AwIjCrV5OTVb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "575aMwOHGbZD"
      },
      "outputs": [],
      "source": [
        "#Take first difference:\n",
        "ts_log_diff = ts_log - ts_log.shift()\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ts_log_diff)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Remember that by shifting one period we create one observation with a null (`NaN`) value.*    "
      ],
      "metadata": {
        "id": "1lKQ0O6wQsgI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBrGwIODGbZE"
      },
      "outputs": [],
      "source": [
        "ts_log_diff.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop missing (`NaN`) values and parse it using our stationary testing function.    "
      ],
      "metadata": {
        "id": "TbuSwbv2Of8d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-LhrBccGbZE"
      },
      "outputs": [],
      "source": [
        "ts_log_diff.dropna(inplace=True)\n",
        "plt.figure(figsize=(20,10))\n",
        "test_stationarity(ts_log_diff)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is stationary because:    \n",
        "* the **mean** and **std variations** have small variations with time.    \n",
        "* **Test Statistic** is less than 10% of the critical values, so we can be 90 % confident that this is stationary.    "
      ],
      "metadata": {
        "id": "dA1fT3cVj-NZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the  `.adf_test()` function we relied upon earlier to test for **stationarity**.     "
      ],
      "metadata": {
        "id": "Q7jhzXP-Igp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform ADF test to check for stationarity\n",
        "adf_test(ts_log_diff)"
      ],
      "metadata": {
        "id": "R2hAkZW-Igp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IAGWXd5skInj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**<u>Decomposing</u>**    \n",
        "\n",
        "Here we model both the trend and the seasonality, then the remaining part of the time series is returned. Pandas has a  function for it. Let’s check it out."
      ],
      "metadata": {
        "id": "GGMVg65EkMtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Additional housekeeping to import `seasonal_decompose` for analysis and treatment of seasonality.*    \n",
        " "
      ],
      "metadata": {
        "id": "LOsxQGQ9OnOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "decomposition = seasonal_decompose(ts_log)"
      ],
      "metadata": {
        "id": "7ra9lLGUO1os"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze a decomposition of the `trend`, it's `seasonal` component and the `residual` value.    \n"
      ],
      "metadata": {
        "id": "roxsf_8fO3e0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7r9l4qUGbZE"
      },
      "outputs": [],
      "source": [
        "trend = decomposition.trend\n",
        "seasonal = decomposition.seasonal\n",
        "residual = decomposition.resid\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(411)\n",
        "plt.plot(ts_log, label='Original')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.plot(trend, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.plot(seasonal,label='Seasonality')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.plot(residual, label='Residuals')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove the trend and seasonality from the Time series and now we can use the residual values. Let’s check stationarity."
      ],
      "metadata": {
        "id": "RTDk23HpktTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing the seasonality residual values and invoking the `test_stationarity` function defined earlier using residuals (`ts_log_decompose`) as an argument.    \n"
      ],
      "metadata": {
        "id": "iHa9mjuIPPrm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s3iZHcbGbZE"
      },
      "outputs": [],
      "source": [
        "ts_log_decompose = residual\n",
        "ts_log_decompose.dropna(inplace=True)\n",
        "plt.figure(figsize=(20,10))\n",
        "test_stationarity(ts_log_decompose)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This is stationary because:    \n",
        "* **Test Statistic** is lower than 1% critical values.    \n",
        "* the **mean** and **std variations** have small variations with time.   \n",
        "\n"
      ],
      "metadata": {
        "id": "K7eJtS0Kk-Fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the `.adf_test()` function we relied upon earlier to test for **stationarity**.     "
      ],
      "metadata": {
        "id": "9ORCey-SIyQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform ADF test to check for stationarity\n",
        "adf_test(ts_log_decompose)"
      ],
      "metadata": {
        "id": "94PV_4tdIyQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "y-N71DhXk_Ox"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONvB79TWGbZF"
      },
      "source": [
        "####5. **Forecasting a Time Series (AR-I-MA)** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLvL-BgnGbZF"
      },
      "source": [
        "#####**<u>ACF & PACF</u>**      \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About ACF and PACF**    \n",
        "\n",
        "\n",
        "*from [Significance of ACF and PACF in Time Series Analysis, TowardDataScience](https://towardsdatascience.com/significance-of-acf-and-pacf-plots-in-time-series-analysis-2fa11a5d10a8)*    \n",
        "\n",
        "\n",
        "\n",
        "**ACF** is an (complete) auto-correlation function which gives us values of auto-correlation of any series with its lagged values. We plot these values along with the confidence band and tada! We have an ACF plot. In simple terms, it describes how well the present value of the series is related with its past values. A time series can have components like trend, seasonality, cyclic and residual. ACF considers all these components while finding correlations hence it’s a ‘complete auto-correlation plot’.    \n",
        "\n",
        "\n",
        "**PACF** is a partial auto-correlation function. Basically instead of finding correlations of present with lags like ACF, it finds correlation of the residuals (which remains after removing the effects which are already explained by the earlier lag(s)) with the next lag value hence ‘partial’ and not ‘complete’ as we remove already found variations before we find the next correlation. So if there is any hidden information in the residual which can be modeled by the next lag, we might get a good correlation and we will keep that next lag as a feature while modeling. Remember while modeling we don’t want to keep too many features which are correlated as that can create multicollinearity issues. Hence we need to retain only the relevant features.    \n",
        "\n"
      ],
      "metadata": {
        "id": "0aSQtcg_REnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional housekeeping to import plot methods `plot_acf()` and `plot_pacf()`.   "
      ],
      "metadata": {
        "id": "zC_5vNatP9_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
      ],
      "metadata": {
        "id": "ztNeMQWJQPkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot of ACF, PACF for the difference in log of time series (`ts_log_diff`).      "
      ],
      "metadata": {
        "id": "EqMdv79sQR3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DETuhe04GbZF"
      },
      "outputs": [],
      "source": [
        "plot_acf(ts_log_diff, lags =20)\n",
        "plot_pacf(ts_log_diff, lags =20)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Housekeeping to import `ARIMA` for Auto-Regressive in Moving Average analysis.    \n"
      ],
      "metadata": {
        "id": "8r4txnAsR2xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "#ACF and PACF plots:\n",
        "from statsmodels.tsa.stattools import acf, pacf  "
      ],
      "metadata": {
        "id": "9TeZJRMXSJic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqxvCzcAGbZF"
      },
      "outputs": [],
      "source": [
        "lag_acf = acf(ts_log_diff, nlags=12)\n",
        "lag_pacf = pacf(ts_log_diff, nlags=12, method='ols')\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "#Plot ACF:    \n",
        "plt.subplot(121)    \n",
        "plt.plot(lag_acf)\n",
        "plt.axhline(y=0,linestyle='--',color='gray')\n",
        "plt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\n",
        "plt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\n",
        "plt.title('Autocorrelation Function')\n",
        "\n",
        "#Plot PACF:\n",
        "plt.subplot(122)\n",
        "plt.plot(lag_pacf)\n",
        "plt.axhline(y=0,linestyle='--',color='gray')\n",
        "plt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\n",
        "plt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\n",
        "plt.title('Partial Autocorrelation Function')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######**Auto-Regressive Model**   \n",
        "\n",
        "\n",
        "**Auto regressive (AR) process** - a time series is said to be AR when present value of the time series can be obtained using previous values of the same time series *i.e.* the present value is weighted average of its past values. Stock prices and global temperature rise can be thought of as an AR processes.    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CsmErR43SPtZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Sd_Jy0CGbZF"
      },
      "outputs": [],
      "source": [
        "#AR model\n",
        "model = ARIMA(ts_log, order=(2,1,0))\n",
        "results_AR = model.fit(disp=-1)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ts_log_diff)\n",
        "plt.plot(results_AR.fittedvalues, color='red')\n",
        "plt.title('RSS: %.4f'% sum((results_AR.fittedvalues - ts_log_diff)**2))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######**Moving Average Model**    \n",
        "\n",
        "**Moving average (MA) process** -  a process where the present value of series is defined as a linear combination of past errors. We assume the errors to be independently distributed with the normal distribution.     \n"
      ],
      "metadata": {
        "id": "y8sjS-VcSXWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1fT374IGbZG"
      },
      "outputs": [],
      "source": [
        "#MA model\n",
        "model = ARIMA(ts_log, order=(0,1,2))\n",
        "results_MA = model.fit(disp=-1)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ts_log_diff)\n",
        "plt.plot(results_MA.fittedvalues, color='red')\n",
        "plt.title('RSS: %.4f'% sum((results_MA.fittedvalues - ts_log_diff)**2))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######**Auto-Regressive in Moving Average Model**    \n"
      ],
      "metadata": {
        "id": "13_Wv4p2SdIp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESUqdeBXGbZG"
      },
      "outputs": [],
      "source": [
        "#ARIMA model\n",
        "model = ARIMA(ts_log, order=(2,1,2))\n",
        "results_ARIMA = model.fit(disp=-1)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ts_log_diff)\n",
        "plt.plot(results_ARIMA.fittedvalues, color='red')\n",
        "plt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues - ts_log_diff)**2))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######**Calculated Targets (Predictions)**    \n"
      ],
      "metadata": {
        "id": "bmQmbVC8Sllb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oC7wn1kGbZG"
      },
      "outputs": [],
      "source": [
        "predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy = True)\n",
        "print(predictions_ARIMA_diff.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYjotHB9GbZG"
      },
      "outputs": [],
      "source": [
        "predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\n",
        "print(predictions_ARIMA_diff_cumsum.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7cIogk8GbZG"
      },
      "outputs": [],
      "source": [
        "predictions_ARIMA_log = pd.Series(ts_log.iloc[0], index = ts_log.index)\n",
        "predictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value = 0)\n",
        "predictions_ARIMA_log.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT20V3nnGbZH"
      },
      "outputs": [],
      "source": [
        "predictions_ARIMA = np.exp(predictions_ARIMA_log)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ts)\n",
        "plt.plot(predictions_ARIMA)\n",
        "plt.title('RMSE: %.4f'% np.sqrt(sum((predictions_ARIMA - ts)**2)/len(ts)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######**Forecasting with 95% Confidence**    \n"
      ],
      "metadata": {
        "id": "B_4TiO17S3Bn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrmsPStFGbZH"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "fig = results_ARIMA.plot_predict(start='1959-01-01', end='1964-01-01',ax=ax)\n",
        "legend = ax.legend(loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diP4SfyOGbZH"
      },
      "source": [
        "######<u>Forecast for next 12 months</u>    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use ARIMA to forecast 12 periods and raise values using `np.exp()` then populate a dataframe (`prediction_df`) with those forecasted values.    \n"
      ],
      "metadata": {
        "id": "vqIAueu9TSdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VSReIU0GbZH"
      },
      "outputs": [],
      "source": [
        "results = results_ARIMA.forecast(steps = 12)\n",
        "converted_results = [(np.exp(x)) for x in [i for i in results]]\n",
        "prediction_df = pd.DataFrame(converted_results)\n",
        "prediction_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "duH1LnpHjfLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reference: Step-by-Step ARIMA      \n",
        "    \n",
        "[Time Series Forecasting using ARIMA Models: A Step-by-Step Guide](https://medium.com/@data-overload/time-series-forecasting-using-arima-models-a-step-by-step-guide-90940d61337c) by DataOverload in Medium.com "
      ],
      "metadata": {
        "id": "QQTNortMTfYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Z97-c0_hT2en"
      }
    }
  ]
}