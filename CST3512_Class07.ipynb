{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CST3512_Class07.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwK6Euggz3HR+Ab7oBcjly",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorPatrickSlatraigh/CST3512/blob/main/CST3512_Class07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CST3512 Class #07\n",
        "**Rationalizing Duplicates in Pandas**\n",
        "\n",
        "from **Finding and removing duplicate rows in Pandas DataFrame**:    \n",
        "\n",
        "**Pandas tips and tricks to help you get started** with data analysis\n",
        "by Bindi Chen. Medium. March 23, 2021.    \n",
        "\n",
        "Available through paywall at: `https://towardsdatascience.com/finding-and-removing-duplicate-rows-in-pandas-dataframe-c6117668631f`\n",
        "\n",
        "*Exercise data from the titanic data set on Kaggle at:* `https://www.kaggle.com/c/titanic/data`\n"
      ],
      "metadata": {
        "id": "OVxSLS44Bcfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstrating the two methods, `duplicated()` and `drop_duplicates()`, for finding and removing duplicate rows, as well as how to modify their behavior to suit specific needs. \n",
        "\n",
        "This notebook is structured as follows:\n",
        "1. Finding duplicate rows\n",
        "2. Counting duplicate and non-duplicate rows\n",
        "3. Extracting duplicate rows with loc\n",
        "4. Determining which duplicates to mark with keep\n",
        "5. Dropping duplicate rows    \n",
        "\n"
      ],
      "metadata": {
        "id": "eK18RCCWCv_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_WZG1MdMO2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 - Module and File Housekeeping    \n",
        "\n",
        "First, import requisite libraries/modules (only pandas)"
      ],
      "metadata": {
        "id": "3KVvXH4DDU4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "loUuarkJBZkP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then attach a handle to the training file set from the titanic dataset sourced from Kaggle `https://www.kaggle.com/c/titanic/data` and read a subset of that data.\n",
        "\n",
        "*note: this example assumes the `train.csv` file has been renamed `titanic_train.csv` and is uploaded to the `\\content` folder of the current Colab session.* \n"
      ],
      "metadata": {
        "id": "arSgd743DstE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function `load_data()` to open a file and return a DataFrame\n",
        "def load_data(): \n",
        "    df_all = pd.read_csv('titanic_train.csv')  # renamed and loaded to \\content\n",
        "    # Take a subset of the first 300 rows, dropping records with missing data\n",
        "    return df_all.loc[:300, ['Survived', 'Pclass', 'Sex', 'Cabin', 'Embarked']].dropna()\n",
        "\n",
        "# create a DataFrame `df` for use in this exercise\n",
        "df = load_data()"
      ],
      "metadata": {
        "id": "4aOH5RLcD3cH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have a look at the dataframe"
      ],
      "metadata": {
        "id": "dO3dOjj-E-bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "CX3eI60KFBnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Find Duplicate Rows     \n",
        "\n",
        "To find duplicates on a specific column, we can simply call duplicated() method on the column.\n"
      ],
      "metadata": {
        "id": "wU1oIbCFE3ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-A\n",
        "# For a single column\n",
        "df.Cabin.duplicated()"
      ],
      "metadata": {
        "id": "C0Y-nAOLFUTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is a boolean Series with the value True denoting duplicate. In other words, the value True means the entry is identical to a previous one.    \n",
        "\n",
        "To take a look at the duplication in the DataFrame as a whole, just call the `duplicated()` method on the DataFrame. It outputs True if an entire row is identical to a previous row.    \n"
      ],
      "metadata": {
        "id": "KNg6eljAHV00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-B\n",
        "# For a DataFrame as a whole\n",
        "df.duplicated()"
      ],
      "metadata": {
        "id": "dGDei1ReFatE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To consider certain columns for identifying duplicates, we can pass a list of columns to the argument subset:     \n"
      ],
      "metadata": {
        "id": "oDLc7bGhHatE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-C\n",
        "# To consider certain columns for identifying duplicates\n",
        "df.duplicated(subset=['Survived', 'Pclass', 'Sex'])"
      ],
      "metadata": {
        "id": "gSQpGLd4Fbem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Counting Duplicates and Non-Duplicates    \n",
        "\n"
      ],
      "metadata": {
        "id": "5h8vRhytFpH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of the `duplicated()` is a boolean Series, and we can add them up to count the number of duplicates. Behind the scene, True gets converted to 1 and False gets converted to 0, then it adds them up."
      ],
      "metadata": {
        "id": "Ft9ksmmXHoko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-A\n",
        "# For a single column\n",
        "df.Cabin.duplicated().sum()"
      ],
      "metadata": {
        "id": "N16gARXdFulP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like before, we can count the duplicate in a DataFrame and on certain columns."
      ],
      "metadata": {
        "id": "kHxw1tuNH1Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-B\n",
        "# For a DataFrame as a whole\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "03-8KPIFF8cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-C\n",
        "# To consider certain columns for identifying duplicates\n",
        "df.duplicated(subset=['Survived', 'Pclass', 'Sex']).sum()"
      ],
      "metadata": {
        "id": "v2Rgn8h8F9Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to count the number of non-duplicates (The number of False), you can invert it with negation (~)and then call `sum()`:"
      ],
      "metadata": {
        "id": "VJmkdpA2H8mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-D\n",
        "# Count the number of non-duplicates\n",
        "(~df.duplicated()).sum()"
      ],
      "metadata": {
        "id": "AIIPEkr_F_ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Extracting Duplicate Rows with `loc`    \n"
      ],
      "metadata": {
        "id": "sOCQemBsIAph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas `duplicated()` returns a boolean Series. However, it is not practical to see a list of True and False when we need to perform some data analysis.\n",
        "We can Pandas `loc` data selector to extract those duplicate rows:"
      ],
      "metadata": {
        "id": "CHMx3uWfIRBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3-A \n",
        "# This allows us to see the rows that were identified by duplicated()\n",
        "df.loc[df.duplicated(), :]"
      ],
      "metadata": {
        "id": "4MnEXiDLIVhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`loc` can take a boolean Series and filter data based on True and False. The first argument `df.duplicated()` will find the rows that were identified by `duplicated()`. The second argument : will display all columns."
      ],
      "metadata": {
        "id": "0wcnblNIIl-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Determining Which Duplicates to Mark with`keep`    \n"
      ],
      "metadata": {
        "id": "OiyJYZ0vIv1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an argument `keep` in Pandas `duplicated()` to determine which duplicates to mark. `keep` defaults to 'first', which means the first occurrence gets kept, and all others get identified as duplicates.\n",
        "We can change it to 'last' keep the last occurrence and mark all others as duplicates."
      ],
      "metadata": {
        "id": "8LDEPOOJI6m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-A \n",
        "# `keep` defaults to `'first'`\n",
        "df.loc[df.duplicated(keep='first'), :]"
      ],
      "metadata": {
        "id": "iFEi7JJ4IsC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-B \n",
        "# `keep` defaults to `'last'`\n",
        "df.loc[df.duplicated(keep='last'), :]"
      ],
      "metadata": {
        "id": "MNmm7ELPJV8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a third option we can use `keep=False`. It marks all duplicates as True and allows us to see all duplicate rows."
      ],
      "metadata": {
        "id": "Lgu-wq7tJTlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-C\n",
        "# There is a third option we can use keep=False. It marks all duplicates as True\n",
        "df.loc[df.duplicated(keep=False), :]"
      ],
      "metadata": {
        "id": "gQGNlC77Jb3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - Dropping Duplicate Rows    "
      ],
      "metadata": {
        "id": "xlKXU2QCJqOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use Pandas built-in method `drop_duplicates()` to drop duplicate rows."
      ],
      "metadata": {
        "id": "oIEsSPoBJ79R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5-A\n",
        "# Note the change in the number of rows before and after dropping duplicates\n",
        "# It is not performed in place by default,\n",
        "df.drop_duplicates()"
      ],
      "metadata": {
        "id": "0r7KUfcvJ-D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, this method returns a new DataFrame with duplicate rows removed. We can set the argument `inplace=True` to remove duplicates from the original DataFrame."
      ],
      "metadata": {
        "id": "xuxOm_fkKeOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5-B\n",
        "# Note the change in the number of rows before and after dropping duplicates\n",
        "# It is not performed in place by default, we can change it to in place by `inplace=True`df.drop_duplicates(inplace=True)\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "Cj65mkOKKilK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Determining which duplicate to keep**    \n",
        "\n",
        "\n",
        "The argument keep can be set for `drop_duplicates()` as well to determine which duplicates to keep. It defaults to `'first'` to keep the first occurrence and drop all other duplicates.    \n",
        "\n",
        "\n",
        "Similarly, we can set keep to `'last'` to keep the last occurrence and drop other duplicates."
      ],
      "metadata": {
        "id": "L7kWBFurLDW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5-C\n",
        "# Use keep='last' to keep the last occurrence \n",
        "df.drop_duplicates(keep='last')"
      ],
      "metadata": {
        "id": "Sa_8WOA9KM92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can set `keep` to **False** to drop all duplicates."
      ],
      "metadata": {
        "id": "EoiBNkkrLWBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5-D \n",
        "# To drop all duplicates\n",
        "df.drop_duplicates(keep=False)"
      ],
      "metadata": {
        "id": "997bDOa_KRSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Considering certain columns for dropping duplicates**    \n",
        "\n",
        "\n",
        "Similarly, to consider certain columns for dropping duplicates, we can pass a list of columns to the argument subset:    \n"
      ],
      "metadata": {
        "id": "py4Q5igjLi27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5-E\n",
        "# Similarly, we can consider a certain columns for dropping duplicates\n",
        "df.drop_duplicates(subset=['Survived', 'Pclass', 'Sex'])"
      ],
      "metadata": {
        "id": "qbNQF1ctKWG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IpZ5vdDhMMR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "cgy6HOzzMRdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas `duplicated()` and `drop_duplicates()` are two quick and convenient methods to find and remove duplicates. It is important to know them as we often need to use them during the data preprocessing and analysis.\n",
        "\n",
        "Hopefully, this article helped save time in learning Pandas.     \n",
        "\n",
        "Check out the documentation for the `duplicated()` and `drop_duplicates()` API and to know about other things you can do.\n",
        "\n",
        "More tutorials on Pandas by Bindi Chen are available on his [GitHub]([https://github.com/BindiChen/machine-learning]). \n",
        "\n",
        "Connect with [Bindi Chen on LinkedIn](https://www.linkedin.com/in/bindi-chen-aa55571a/).\n"
      ],
      "metadata": {
        "id": "pYtuj-thMTsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AnyX9KZTNZIK"
      }
    }
  ]
}