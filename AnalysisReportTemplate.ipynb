{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnalysisReportTemplate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorPatrickSlatraigh/CST3512/blob/main/AnalysisReportTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysis Report Template    \n",
        "\n",
        "\n",
        "**A shared resource for the organization of data science analysis and report presentation.**\n",
        "\n",
        "Prepared by CUNY CityTech CST3512 class, Spring 2022.   \n",
        "\n"
      ],
      "metadata": {
        "id": "Ar1dlppwcrPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OUTLINE**    \n",
        "\n",
        "* Executive Summary   \n",
        "* Background   \n",
        "* Problem Statement   \n",
        "* Approach    \n",
        "* Findings    \n",
        "* Model/Analysis Design   \n",
        "* One or Themes (deeper findings)    \n",
        "* Implications (so what?)     \n",
        "* Recommendation(s)   \n",
        "* Next Steps (implement/additional-research)   \n",
        "\n",
        "\n",
        "* APPENDICES    \n",
        "1.   Footnotes    \n",
        "2.   Glossary of terms    \n",
        "3.   Additional reading   \n"
      ],
      "metadata": {
        "id": "0PqttnLniYOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Executive Summary    \n",
        "\n"
      ],
      "metadata": {
        "id": "WFcvmzu84RLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Background    \n",
        "\n"
      ],
      "metadata": {
        "id": "SVGcavwo4RH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem Statement    \n",
        "\n"
      ],
      "metadata": {
        "id": "pba2uEEx4Q_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Approach    \n",
        "\n"
      ],
      "metadata": {
        "id": "jokE8gKI4Q4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Findings    \n"
      ],
      "metadata": {
        "id": "9Mlks0rJ4QxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model/Design Analysis    \n",
        "\n"
      ],
      "metadata": {
        "id": "PVKQGKjN4QqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Themes    \n",
        "\n"
      ],
      "metadata": {
        "id": "SMJqnnHq4QTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implications    \n",
        "\n"
      ],
      "metadata": {
        "id": "Wyy9CAVY48-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Recommendations    \n"
      ],
      "metadata": {
        "id": "Yn8HoXIp5AMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Next Steps    \n"
      ],
      "metadata": {
        "id": "GOh4OKlz5Ewa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZgSofQ0DR9_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Appendix 1 - Footnotes    \n"
      ],
      "metadata": {
        "id": "0I48gB7t5IhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aWKvP93UR7df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Appendix 2 - Glossary of Terms    \n"
      ],
      "metadata": {
        "id": "J05taHqH5d-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1PBy-yNbR6qS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Appendix 3 - Additional Reading    \n"
      ],
      "metadata": {
        "id": "BbO9vRS75hfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Q9r2AzaojPc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Appendix 4 - RESOURCES - Data Sources to Consider   \n",
        "\n",
        "* **Kaggle** - Data sources across disciplines, time periods, and geographies\n",
        "* **OWID** - Our World in Data\n",
        "* **United Nations** -- Many global datasets\n",
        "* **Project Gutenberg** - Open-source text of works of literature\n",
        "* **Data.gov** - A variety of sources of data on government measures    \n",
        "* **U.S. Bureau of Labor Statistics (BLS)** -- Labor and employment data in the United States    \n",
        "* **NYC Open Data** - Multiple data sources from New York City Government\n",
        "* **FBI Uniform Crime Reporting (UCR)** -- Aggregated law enforcement data from across the United States\n",
        "* **Yahoo Finance** - Time-series market data and a variety of data sources about public companies\n",
        "* **EDGAR** - Security and Exchange Commission (SEC) data of corporate filings\n",
        "* **Health Data** - Various data sources\n",
        "* **Weather** - Various data sources\n",
        "* **Geolocation** - Data sources on Named Entity : Longitude/Lattitude maps, and other location-specific data   \n",
        "\n",
        "\n",
        "*note: **Google** curates a [catalog of open data sources](google.com/publicdata/directory)*\n"
      ],
      "metadata": {
        "id": "HmsMn9RCjQgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Kaggle     \n",
        "\n",
        "The following dataset contains five years of data regarding Netflix's stock prices. Ranging from February 5th, 2018 - February 5th, 2022.\n",
        "\n",
        "https://www.kaggle.com/datasets/jainilcoder/netflix-stock-price-prediction"
      ],
      "metadata": {
        "id": "UskbroIclq-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###OWID     \n",
        "\n",
        "place OWDI info and links in this section"
      ],
      "metadata": {
        "id": "-T6hey5olyjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###United Nations    \n",
        "\n",
        "place UN info and links here    \n"
      ],
      "metadata": {
        "id": "AXetTnlKwY03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Project Gutenberg     \n",
        "\n",
        "place Project Gutenberg info and links in this section   \n"
      ],
      "metadata": {
        "id": "xP8m-_Nul-I-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data.gov    \n",
        "\n",
        "place data.gov info and links in this section    \n",
        "\n"
      ],
      "metadata": {
        "id": "f6pRUqRNmG6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###U.S. Bureau of Labor Statistics (BLS)    \n",
        "\n",
        "place BLS info here.    \n",
        "\n",
        "*note: more online at https://www.bls.gov/*"
      ],
      "metadata": {
        "id": "O726wlw5wftc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NYC Open Data    \n",
        "\n",
        "place New York City Open Data info and links in this section    \n"
      ],
      "metadata": {
        "id": "OzgpRLetmNC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://data.gov"
      ],
      "metadata": {
        "id": "oum-HlvHpnzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###FBI Uniform Crime Reporting (UCR)    \n",
        "\n",
        "Aggregate data from law enforcement across the United States at: https://www.fbi.gov/services/cjis/ucr    \n"
      ],
      "metadata": {
        "id": "qVPmeZkUvH7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yahoo Finance    \n",
        "\n",
        "place Yahoo Finance info and links here    \n",
        "\n"
      ],
      "metadata": {
        "id": "5CMqlhKOmbGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EDGAR (U.S. SEC)    \n",
        "\n",
        "place SEC Edgar info and links in this section    \n"
      ],
      "metadata": {
        "id": "is50vYoPmmFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Weather \n",
        "\n",
        "1.    [OpenWeatherMap](https://openweathermap.org/weathermap) - Dynamic weather maps.    \n",
        "\n",
        "2.    [NOAA's Geoplatform](https://www.climate.gov/maps-data/all) - Data, maps, analytics on weather for U.S. National Oceanographic and Atmospheric Administration.     \n"
      ],
      "metadata": {
        "id": "BaySwbV-5453"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Google Catalog of Open Data    \n",
        "\n",
        "place Google Catalog of Open Data info and links here.\n",
        "\n",
        "See `google.com/publicdata/directory` for the home page."
      ],
      "metadata": {
        "id": "iv4rE81xmwC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DataWorld.com    \n",
        "\n",
        "[Data.World](https://data.world) is a collection of availabl data source for research and exercises.    \n"
      ],
      "metadata": {
        "id": "RCc1YgVQbEvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Appendix 5 - Data Discovery Approach"
      ],
      "metadata": {
        "id": "OJ5RDAm6SBXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each problem and the data sources considered will raise unique considerations but there are several typical steps to data extraction, discovery, and transformation which are helpful to consider.    \n",
        "\n",
        "The following is derived from the work of Anmol Tomar in CodeX, entitled \"[Every Data Analysis in 10 steps!  Adding structure to your data analysis!](https://medium.com/codex/every-data-analysis-in-10-steps-960dc7e7f00b)\""
      ],
      "metadata": {
        "id": "UGMvsEJYSHV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###File Upload"
      ],
      "metadata": {
        "id": "pygOTl3wWVxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMDB Dataset**    \n",
        "\n",
        "For  illustration purposes, this analysis uses the Kaggle IMDB dataset for the top 1000 movies to understand the features/traits of top IMDB movies by applying a 10 step-process.    *The Kaggle file used in this notebook differs from the source file used by Anmol Tomar in the article referenced above.*  \n",
        "\n",
        "A copy of the file is hosted on Professor Patrick's GitHub and can be accsed with `!curl` to upload a copy to the `content` folder in Colab.    \n"
      ],
      "metadata": {
        "id": "T_eWdtgSS3Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://raw.githubusercontent.com/ProfessorPatrickSlatraigh/data/main/IMDB_top_1000.csv\" -o imdb_top_1000.csv"
      ],
      "metadata": {
        "id": "E0WhUYu4Vvxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import Packages    \n",
        "\n",
        "The load, discovery, and transformation steps will only require that the `pandas` and `matplotlib` packages be imported.    \n",
        "\n",
        "To add functionality to data tables in Colab, import `data_table` from `google.colab`."
      ],
      "metadata": {
        "id": "6UWCV11SWS7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import our packages \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "BrWmty-JTQaC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Read the Data into a Dataframe    \n"
      ],
      "metadata": {
        "id": "tmcsf6BMWsor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the data\n",
        "df_movies =  pd.read_csv('imdb_top_1000.csv')"
      ],
      "metadata": {
        "id": "A3uuHsALW40Q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Summarize the Columns    \n",
        "\n"
      ],
      "metadata": {
        "id": "14FSXQL0W8Q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of the columns   \n",
        "df_movies.describe(include = 'all')"
      ],
      "metadata": {
        "id": "zAJV5RJwXA8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A detailed pivot table can be viewed as well to peruse the data.    "
      ],
      "metadata": {
        "id": "2ybNwMiiZAl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# query the detail in the dataframe\n",
        "df_movies"
      ],
      "metadata": {
        "id": "vAVYKKHIYmU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Data Types    \n",
        "\n",
        "The next step is to do a sanity check of the data types of the columns of the dataframe. If there are some incorrect data types they can be corrected in this step."
      ],
      "metadata": {
        "id": "1kwBCvrgYHAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the datatypes \n",
        "print(df_movies.dtypes)"
      ],
      "metadata": {
        "id": "VTv3ecNnZhgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The field `Duration` is a string (object data type) with the runtime in minutes followed by the term 'min'.  A new column can be generated for `runtime` as a float by assigning the result of a split of `Duration` and the transformation of the first element in the resulting list into a float. "
      ],
      "metadata": {
        "id": "nsJ6aaA-b3OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the numeric value of movie Duration to a new column Runtime \n",
        "df_movies[['Runtime', 'Unit']] = df_movies[\"Duration\"].str.split(' ', 1, expand=True)\n",
        "df_movies['Runtime'] = df_movies['Runtime'].astype(int)\n",
        "del df_movies['Unit']"
      ],
      "metadata": {
        "id": "9MS8rNJFc3zF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the dataframe after the transformation   \n",
        "df_movies"
      ],
      "metadata": {
        "id": "G6WPznU5djF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another approach would simply replace the `Duration` column in place with it's float value\n",
        "# Transformting `Duration` into int \n",
        "\n",
        "# >>> Remove the comment from the following line of code to try it\n",
        "# df_movies['Duration'] = df_movies['Duration'].str.replace(' min','').astype(int)\n"
      ],
      "metadata": {
        "id": "dmfXl_qwgHYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Review the data types of each column again\n",
        "df_movies.dtypes"
      ],
      "metadata": {
        "id": "AtyXzTYegyxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Missing Values    \n",
        "\n",
        "The third step is to find the number of missing values across the columns of the dataframe. It’s important to understand the count of nulls so determine how best to treat them.    "
      ],
      "metadata": {
        "id": "DIKYq0WGhBYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find nulls \n",
        "df_movies.isnull().sum()"
      ],
      "metadata": {
        "id": "UNaeaIcmhTbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Missing values treatment    \n",
        "\n",
        "Using the count of missing values and any other descriptive statistics applicable, the next step is to treat the columns with missing values.    \n",
        "\n",
        "For illustration purposes, the nulls are filled with the mean value of the columns, although there are more sophisticated methods of missing value treatment.   \n"
      ],
      "metadata": {
        "id": "9PUaQFA-h5Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing nulls with mean for numeric values and mode for categorical values\n",
        "\n",
        "df_movies['Metascore'].fillna(df_movies['Metascore'].mean())\n",
        "\n",
        "df_movies['Certificate'].fillna(df_movies['Certificate'].mode())\n"
      ],
      "metadata": {
        "id": "Qh1_gHzwh7ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies.head()\n"
      ],
      "metadata": {
        "id": "x_f_BvBoinYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Outliers    \n",
        "\n",
        "The fifth step is to check for outliers. There are multiple ways of checking the outliers, the graphical method vis presented here. Two continuous variables (`Metascore` and `Runtime`) have been select to be checked for outliers by evaluating a histogram for each column.    "
      ],
      "metadata": {
        "id": "c7CRu70-jb2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Metascores \n",
        "plt.hist(df_movies['Metascore'],bins = 25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_3D4aRxZjdAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Runtimes \n",
        "plt.hist(df_movies['Runtime'],bins = 25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bWG3ilD3jwKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Outlier Treatment\n",
        "\n",
        "\n",
        "The next step is to treat the outliers observed in the previous step. There are different ways of treating the outliers such as:     \n",
        "1. Capping the minimum and maximum value limits\n",
        "2. Removing the rows with outlier values   \n",
        "\n",
        "\n",
        "Although there is nothing off with the distribution of Metascores, for illustration purposes, the minimum `Metascore` value is capped at 65.    \n",
        "\n",
        "\n",
        "And with respect to the Runtimes, any rows with a `Runtime` in excess of 200 is deleted as are rows with a `Runtime` of less than 60.   \n",
        "\n"
      ],
      "metadata": {
        "id": "IBl-AtQFkAai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Capping the minimum Metascore to 65\n",
        "df_movies.loc[df_movies['Metascore'] < 65,'Metascore'] = 65\n",
        "\n",
        "#check the minimum score \n",
        "df_movies['Metascore'].min()\n",
        "# output : 65.0"
      ],
      "metadata": {
        "id": "-kJvPiczkuxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping any rows where Runtime exceeeds 200 or is below 60\n",
        "df_movies.drop(df_movies[(df_movies.Runtime > 200) | (df_movies.Runtime < 60)].index, inplace=True)  \n"
      ],
      "metadata": {
        "id": "W9ielgEJl8GP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of Runtimes \n",
        "plt.hist(df_movies['Runtime'],bins = 25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4Q9UAspZmXvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. Who    \n",
        "\n",
        "\n",
        "The seventh step to answer are questions related to people, members, stakeholders, etc. \n",
        "\n",
        "In films, there are actors, directors, and cast members.  Some 'who' questions to raise could include:  \n",
        "\n",
        "* Who has directed the most number of top IMDB movies? (univariate)    \n",
        "\n",
        "\n",
        "* Who has acted in most top IMDB movies? (univariate)    \n",
        "\n",
        "\n",
        "* Which Actor-Director combination has the most top IMDB movies? (bivariate)    \n",
        "\n",
        "\n",
        "* Who provided the most music in top IMDB movies ? (Data not available)    \n",
        "\n",
        "\n",
        "And More …    \n",
        "\n"
      ],
      "metadata": {
        "id": "YXncGAO6pfLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*to use the code in the following snippet, extraction of data values from the `Cast` column would be required as a preliminary transformation.*\n"
      ],
      "metadata": {
        "id": "lQwa4C8wquzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### >>> The sample code here relies on columns in the original dataset used by Anmol Tomar\n",
        "### >>> The columns required by the code in this snippet are not available in the Kaggle dataset\n",
        "\n",
        "## Who has directed the most number of top IMDB movies ?\n",
        "# df_movies.groupby(['Director']).agg({'Series_Title':'count'}).reset_index().rename(columns = {'Series_Title':'count'}).\\\n",
        "# sort_values('count',ascending = False).head(5)\n",
        "\n",
        "## Who has acted in the most number of top movies \n",
        "# df_movies.groupby(['Star1']).agg({'Series_Title':'count'}).reset_index().rename(columns = {'Series_Title':'count'}).\\\n",
        "# sort_values('count',ascending = False).head(5)\n",
        "\n",
        "## Director - Actor works best \n",
        "# df_movies.groupby(['Director','Star1'])['Series_Title'].count().reset_index().\\\n",
        "# rename(columns = {'Series_Title':'Count'}).sort_values('Count',ascending = False).head(5)    \n"
      ],
      "metadata": {
        "id": "bPSe912Mpxvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. When    \n",
        "\n",
        "\n",
        "The eighth step is to answer questions related to the time dimension (year, quarter, month, week, day, time-of-day, hour, minute, etc.)    \n",
        "\n",
        "Considering film data, the following type of question could be asked:    \n",
        "\n",
        "\n",
        "* Find the years with most movies in IMDB top 1000 ? (univariate)    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aTen4oxarnHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*to use the code in the following snippet, extraction of data values from the `Title` column would be required as a preliminary transformation.*"
      ],
      "metadata": {
        "id": "VwE9jyYssYyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### >>> The sample code here relies on columns in the original dataset used by Anmol Tomar\n",
        "### >>> The columns required by the code in this snippet are not available in the Kaggle dataset\n",
        "\n",
        "## Finding years with most movies in top 1000\n",
        "# year_dis = df_movies.groupby('Released_Year')['Series_Title'].count().reset_index().\\\n",
        "# rename(columns = {'Series_Title':'Count'}).sort_values('Count',ascending = False).head(10)\n",
        "\n",
        "# plt.bar(year_dis['Released_Year'].astype(str), year_dis['Count'], width = 0.5)\n",
        "# plt.xlabel('Years')\n",
        "# plt.ylabel('Number of Movies')\n",
        "# plt.title('Years with most movies in IMDB top 1000')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "3Po6QyiMqgdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9. Where    \n",
        "\n",
        "The ninth steo is to look at the things from the “place” perspective, for example, country, state, regions etc.  Geolocation can also be used in determing the 'where' attribute of data. \n",
        "\n",
        "For film data, the following question could be posed:    \n",
        "\n",
        "\n",
        "* Find countries with most movies in IMDB top 1000.\n",
        "\n",
        "\n",
        "The dataset does not have the data to answer this question.   \n",
        "Research should be as exhaustive as possible and not limited based on data availability.  Additional sources or enrichment approaches should be considered to answer pertinent questions.    \n",
        "\n"
      ],
      "metadata": {
        "id": "adAccQcNsdgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10. What/Which/How    \n",
        "\n",
        "\n",
        "The tenth and final step is formulating questions about aspects not covered in the first nine steps. These questions are not related to people, place, or time but everything apart from these. Formulating such questions can be quite subjective and takes some time and experience to develop intuition and a facility.\n",
        "\n",
        "With respect to film data, such question might include:    \n",
        "\n",
        "* Which genres are featured most in the top 1000?\n",
        "\n",
        "\n",
        "* What is the duration of the top movies?\n",
        "\n",
        "\n",
        "* What is the correlation between the rating and gross earning?\n",
        "\n",
        "\n",
        "and more…\n",
        "\n",
        "For illustration purposes, the first question is approached using the following code:\n",
        "\n"
      ],
      "metadata": {
        "id": "Iz0se6PdtOw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Which genres of film are featured most in top 1000 ? \n",
        "genre_dis = df_movies.groupby('Genre')['Title'].count().reset_index().\\\n",
        "rename(columns = {'Title':'Count'}).sort_values('Count',ascending = False).head(5)\n",
        "fig, ax = plt.subplots()\n",
        "plt.bar(genre_dis['Genre'], genre_dis['Count'], width = 0.5)\n",
        "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qyzK4zcEuK32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mEitLngMuq3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can refine the exercises in this appendix through the inclusion of the requisite trasnformations to wrangle the data required for additional analysis.   \n"
      ],
      "metadata": {
        "id": "2QnNfKqKueQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "z6yO_9P9li_u"
      }
    }
  ]
}